import sys

sys.path.insert(1, "/home/vinicius/storage1/projects/GrayData-Analysis")


import argparse
import os
import pickle

import numpy as np
import xarray as xr
from brainconn.centrality import kcoreness_centrality_bu
from frites.dataset import DatasetEphy
from frites.estimator import GCMIEstimator
from frites.utils import parallel_func
from frites.workflow import WfMi
from tqdm import tqdm

from config import freqs, get_dates, return_delay_split
from GDa.loader import loader
from GDa.session import session_info
from GDa.util import average_stages
from utils import *





def get_area_mapping(unique_areas):
    """
    Create a mapping from unique region areas to their indices.

    Args:
        unique_areas (ndarray): An array of unique region areas.

    Returns:
        dict: A dictionary mapping region areas to their corresponding indices.

    """
    area2idx = dict(zip(unique_areas, range(len(unique_areas))))
    return area2idx


def get_unique_areas_mapping(session, ttype=1, br=1):
    """
    Get unique region areas and their mapping to indices for a session.

    Args:
        session (str): The session identifier.
        ttype (int, optional): The ttype identifier (default is 1).
        br (int, optional): The br identifier (default is 1).

    Returns:
        tuple: A tuple containing two elements:
            - unique_areas (ndarray): An array of unique region areas.
            - area2idx (dict): A dictionary mapping region areas to their indices.

    """
    unique_areas = []
    for t in range(5):
        for freq in freqs:
            areas, _, _ = load_areas_times(
                session, stage_labels[t], freq, ttype=ttype, br=br
            )
            unique_areas += [np.unique(np.hstack(areas))]
    unique_areas = np.unique(np.concatenate(unique_areas))
    return unique_areas, get_area_mapping(unique_areas)


def load_areas_times(session, epoch, freq, ttype=1, br=1, surr=1, trials=False):
    """
    Load node region and time labels from pickle files.

    Args:
        session (str): The session identifier.
        epoch (int): The epoch identifier.
        freq (str): The frequency identifier.
        ttype (int, optional): The ttype identifier (default is 1).
        br (int, optional): The br identifier (default is 1).
        trials (bool, optional): Whether to load trials data (default is False).

    Returns:
        tuple: A tuple containing two or three elements, depending on the 'trials' parameter.
            - areas (list): List of node region labels.
            - times (list): List of node time labels.
            - trials (list, optional): List of node trial labels (only if trials=True).

    """

    # Load node region label
    fname = os.path.join(
        _path_to_ava,
        f"areas_tt_{ttype}_br_{br}_{epoch}_{session}_freq_{freq}_thr_3_decim_5_surr_{surr}.pkl",
    )
    with open(fname, "rb") as f:
        areas = pickle.load(f)

    # Load node time labelé
    fname = os.path.join(
        _path_to_ava,
        f"times_tt_{ttype}_br_{br}_{epoch}_{session}_freq_{freq}_thr_3_decim_5_surr_{surr}.pkl",
    )
    with open(fname, "rb") as f:
        times = pickle.load(f)

    # Load node time labelé
    fname = os.path.join(
        _path_to_ava,
        f"stim_tt_{ttype}_br_{br}_{epoch}_{session}_freq_{freq}_thr_3_decim_5_surr_{surr}.pkl",
    )
    with open(fname, "rb") as f:
        stims = pickle.load(f)

    if trials:
        # Load node time labelé
        fname = os.path.join(
            _path_to_ava,
            f"trials_tt_{ttype}_br_{br}_{epoch}_{session}_freq_{freq}_thr_3_decim_5_surr_{surr}.pkl",
        )
        with open(fname, "rb") as f:
            trials = pickle.load(f)

        return areas, times, stims, trials

    return areas, times, stims


def get_coavalanche_matrix(areas, times, unique_areas, area2idx):
    """
    Calculate the coavalanche matrix, precedence matrix, and delta values.

    Args:
        areas (list): List of areas.
        times (list): List of times.

    Returns:
        tuple: A tuple containing the coavalanche matrix, precedence matrix, and delta values.

    Raises:
        None
    """

    navalanches = len(areas)

    # unique_areas = np.unique(np.hstack(areas))
    # area2idx = get_area_mapping(unique_areas)
    n_unique_areas = len(unique_areas)

    T = np.zeros((n_unique_areas, n_unique_areas))
    P = np.zeros((n_unique_areas, n_unique_areas))

    delta = np.zeros(navalanches)

    for i in range(navalanches):
        ua = np.unique(areas[i])
        # Index of areas in the avalanche
        idx = [area2idx[area] for area in ua]
        # Time slice of each area
        tava = times[i].astype(int)
        # Avalanche duration
        delta[i] = tava.max() - tava.min()
        # Coactivation
        T[np.ix_(idx, idx)] += 1
        # Precedence
        min_times = []
        for a in ua:
            min_times += [times[i].astype(int)[areas[i] == a].min()]
        min_times = np.array(min_times)
        prec = np.array(min_times)[:, None] < np.array(min_times)
        P[np.ix_(idx, idx)] += prec.astype(int)

    np.fill_diagonal(T, 0)

    T = xr.DataArray(
        T / navalanches,
        dims=("sources", "targets"),
        coords=(unique_areas, unique_areas),
    )
    P = xr.DataArray(
        P / navalanches,
        dims=("sources", "targets"),
        coords=(unique_areas, unique_areas),
    )

    return T, P, delta


def get_st_coavalanche_matrix(areas, times, unique_areas, area2idx, trials):
    """
    Calculate the spatiotemporal co-avalanche matrix for given data.

    Args:
        areas (list): List of node region labels.
        times (list): List of node time labels.
        unique_areas (list): List of unique region labels.
        area2idx (dict): A dictionary mapping region labels to indices.
        trials (list): List of trial labels.

    Returns:
        xr.DataArray: A spatiotemporal co-avalanche matrix as a DataArray,
            with "trials" as the coordinate.

    """

    unique_trials = np.unique(trials)

    T = []

    for trial in unique_trials:

        areas_sel = []
        times_sel = []

        trials_indexes = np.where(trials == trial)[0]
        for i in trials_indexes:
            areas_sel += [areas[i]]
            times_sel += [times[i]]
        out, _, _ = get_coavalanche_matrix(areas_sel, times_sel, unique_areas, area2idx)
        T += [out]
    return xr.concat(T, "trials").assign_coords({"trials": unique_trials})


def get_trials_stim_map(trials, stims):
    unique_trials = np.unique(trials)
    unique_stim = []
    for trial in unique_trials:
        unique_stim += [np.unique(stims[np.where(unique_trials == trial)])]
    unique_stim = np.hstack(unique_stim)

    return dict(zip(unique_trials, unique_stim))


def get_agg_graph(areas, times, unique_areas, area2idx):
    """
    Compute an aggregated coavalanching graph from areas and times data.

    Inputs:
    ------
    areas : array-like
        Array-like object containing the areas present in the avalanche.
    times : array-like
        Array-like object containing the times associated with the areas.
    unique_areas : array-like
        Array-like object containing unique area identifiers.

    Returns:
    -------
    agg : 2D boolean array
        Aggregated coavalanching graph indicating the coavalanching relationships
        between unique areas. True indicates a coavalanching relationship, and False indicates
        the absence of a coavalanching relationship.
    """
    # Get mapping area->index
    # area2idx = get_area_mapping(unique_areas)
    # Unique areas present in the avalanche
    ua = np.unique(areas)
    # Get index of each area in the present avalanche
    idx = np.array([area2idx[area] for area in areas])
    # Normalize times to start from zero
    t = times.astype(int)
    t = t - t.min()
    # Store frames of coavalanching networks
    ar = np.zeros((len(unique_areas), len(unique_areas), t.max() + 1))
    for i in t:
        A = np.zeros_like(unique_areas, dtype=int)
        A[idx[t == i]] = 1
        ar[..., i] = np.outer(A, A)

    agg = ar.mean(axis=-1) > 0

    return agg


def compute_agg_graphs_coreness(
    areas, times, unique_areas, area2idx, n_jobs=1, verbose=False
):
    """
    Compute the coreness of aggregated coavalanching graphs.

    Inputs:
    ------
    areas : list of 2D arrays
        List of 2D arrays representing the areas in each avalanche.
    times : list of 1D arrays
        List of 1D arrays representing the time points in each avalanche.
    n_jobs : int, optional
        Number of parallel jobs to run. Default is 1.
    verbose : bool, optional
        Verbosity flag. If True, progress information is printed. Default is False.

    Returns:
    -------
    kcore : DataArray
        DataArray containing the coreness values for each unique area in the aggregated
        coavalanching graphs. The dimensions are ('ava', 'roi'), and the coordinate
        'roi' represents the unique areas.
    """
    # Get unique areas
    # unique_areas = np.unique(np.hstack(areas))
    # Number of avalanches
    nava = len(areas)

    # Generate aggregated networks
    parallel, p_fun = parallel_func(
        get_agg_graph, n_jobs=n_jobs, verbose=verbose, total=nava
    )

    agg = parallel(
        p_fun(areas[n], times[n], unique_areas, area2idx) for n in range(nava)
    )

    agg = np.stack(agg, axis=0)

    def __fkcore(agg_):
        out, _ = kcoreness_centrality_bu(agg_)
        return out

    # Generate aggregated networks
    parallel, p_fun = parallel_func(__fkcore, n_jobs=n_jobs, verbose=False, total=nava)

    kcore = parallel(p_fun(agg_) for agg_ in agg)

    kcore = xr.DataArray(kcore, dims=("ava", "roi"), coords={"roi": unique_areas})

    return kcore


def single_trial_coreness(
    areas, times, stims, trials, unique_areas, area2idx, epoch, freq, ttype=1, br=0
):

    unique_trials = np.unique(trials)

    kcore = []

    for trial in unique_trials:

        areas_sel = []
        times_sel = []

        trials_indexes = np.where(trials == trial)[0]

        for i in trials_indexes:
            areas_sel += [areas[i]]
            times_sel += [times[i]]

        kcore += [
            compute_agg_graphs_coreness(
                areas_sel, times_sel, unique_areas, area2idx, n_jobs=1, verbose=False
            ).mean("ava")
        ]

    kcore = xr.concat(kcore, "trials").assign_coords({"trials": unique_trials})

    return kcore





_ROOT = os.path.expanduser("~/funcog/gda/")


tt = 1
br = 1
monkey = "lucy"
freqs = freqs.astype(int)
stage_labels = ["P", "S", "D1", "D2", "Dm"]

sessions = get_dates(monkey)
_path_to_ava = os.path.expanduser(f"~/funcog/gda/Results/{monkey}/avalanches/")





def get_CCS(session):
    CCS = []
    TRIALS = []
    STIMS = []
    for freq in freqs:
        T = []
        for epoch in stage_labels:
            areas, times, stims, trials = load_areas_times(
                session, epoch, freq, ttype=tt, br=br, trials=True
            )

            TRIALS += [trials]
            STIMS += [stims]

            unique_areas, area2idx = get_unique_areas_mapping(session)

            T += [
                get_st_coavalanche_matrix(areas, times, unique_areas, area2idx, trials)
            ]
        CCS += [xr.concat(T, "times").sum("sources")]

    trials2stim = get_trials_stim_map(np.hstack(TRIALS), np.hstack(STIMS))

    CCS = (
        xr.concat(CCS, "freqs")
        .assign_coords({"freqs": freqs})
        .rename({"targets": "roi"})
        .transpose("times", "roi", "freqs", "trials")
    )

    stim_vec = [trials2stim[t] for t in CCS.trials.data]

    CCS = CCS.assign_coords({"trials": stim_vec})

    return CCS.transpose("trials", "roi", "freqs", "times")


"""
def get_CCS(session):
    CCS = []
    TRIALS = []
    STIMS = []
    for freq in freqs:
        T = []
        for epoch in stage_labels:
            areas, times, stims, trials = load_areas_times(
                session, epoch, freq, ttype=tt, br=br, trials=True
            )

            TRIALS += [trials]
            STIMS += [stims]

            unique_areas, area2idx = get_unique_areas_mapping(session)

            T += [
                single_trial_coreness(
                    areas,
                    times,
                    stims,
                    trials,
                    unique_areas,
                    area2idx,
                    epoch,
                    freq,
                    ttype=tt,
                    br=br,
                )
            ]
        CCS += [xr.concat(T, "times")]

    trials2stim = get_trials_stim_map(np.hstack(TRIALS), np.hstack(STIMS))

    CCS = (
        xr.concat(CCS, "freqs")
        .assign_coords({"freqs": freqs})
        .transpose("trials", "roi", "freqs", "times")
    )

    stim_vec = [trials2stim[t] for t in CCS.trials.data]

    CCS = CCS.assign_coords({"trials": stim_vec})
    CCS = (CCS.fillna(0)).astype(int)

    return CCS
    """;


"""
for s_id in tqdm(sessions[4:]):
    kcore = get_CCS(s_id)
    kcore.to_netcdf(f"coreness/kcore_lucy_{s_id}.nc")
""";


sxx = []
stim = []
for s_id in tqdm(sessions):

    CCS = get_CCS(s_id).fillna(0)
    """
    CCS = (
        xr.load_dataarray(f"coreness/kcore_lucy_{s_id}.nc")
        .fillna(0)
        .groupby("trials")
        .mean("trials")
    )
    """
    sxx += [CCS.isel(roi=[r]) for r in range(len(CCS["roi"]))]
    stim += [CCS.trials.data.astype(int)] * len(CCS["roi"])





# Convert to DatasetEphy
dt = DatasetEphy(sxx, y=stim, nb_min_suj=10, times="times", roi="roi")

mi_type = "cd"
inference = "rfx"
kernel = None

mcp = "fdr"

mi_type = "cd"

estimator = GCMIEstimator(
    mi_type="cd",
    copnorm=True,
    biascorrect=True,
    demeaned=False,
    tensor=True,
    gpu=False,
    verbose=None,
)
wf = WfMi(mi_type, inference, verbose=True, kernel=kernel, estimator=estimator)

kw = dict(n_jobs=30, n_perm=500)
cluster_th = None

mi, pvalues = wf.fit(dt, mcp=mcp, cluster_th=cluster_th, **kw)

tvals = wf.tvalues


tvals = node_xr_remove_sca(((pvalues < 0.01) * wf.tvalues).sel(freqs=27))


from GDa.flatmap.flatmap import flatmap


def plot_brain_areas(ax, values, vmax):

    import matplotlib as mpl
    import matplotlib.patches as mpatches

    areas = values.roi.data  # np.asarray([area for area in areas_dict.keys()])
    areas = [a.lower() for a in areas]
    fmap = flatmap(values.data, areas)

    fmap.plot(
        ax,
        ax_colorbar=None,
        cbar_title=None,
        alpha=0.4,
        colormap="hot_r",
        colors=None,
        vmin=0,
        vmax=vmax,
    )


import matplotlib.pyplot as plt

plt.figure(figsize=(15, 5), dpi=600)
for i in range(5):
    ax = plt.subplot(1, 5, i + 1)
    plot_brain_areas(ax, tvals.sel(times=i), 5)
    plt.title(stage_labels[i])



