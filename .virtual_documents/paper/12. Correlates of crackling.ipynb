


import sys

sys.path.insert(1, "/home/vinicius/storage1/projects/GrayData-Analysis")


import os

import matplotlib.pyplot as plt
import numpy as np
import pandas as pd
import scipy
import scipy.stats as stats
import seaborn as sns
import xarray as xr
from frites.conn.conn_tf import _tf_decomp
from frites.stats import confidence_interval
from frites.utils import parallel_func
from mne.filter import filter_data
from mne.stats import fdr_correction
from tqdm import tqdm

from config import get_dates, return_delay_split, return_evt_dt
from GDa.loader import loader
from GDa.session import session
from GDa.stats.bursting import find_start_end


import numpy as np
from matplotlib import pyplot as plt
from mne import Epochs, create_info
from mne.baseline import rescale
from mne.io import RawArray
from mne.time_frequency import (
    AverageTFR,
    tfr_array_morlet,
    tfr_morlet,
    tfr_multitaper,
    tfr_stockwell,
)
from mne.viz import centers_to_edges

print(__doc__)

sfreq = 1000.0
ch_names = ["SIM0001", "SIM0002"]
ch_types = ["grad", "grad"]
info = create_info(ch_names=ch_names, sfreq=sfreq, ch_types=ch_types)

n_times = 1024  # Just over 1 second epochs
n_epochs = 40
seed = 42
rng = np.random.RandomState(seed)
data = rng.randn(len(ch_names), n_times * n_epochs + 200)  # buffer

# Add a 50 Hz sinusoidal burst to the noise and ramp it.
t = np.arange(n_times, dtype=np.float64) / sfreq
signal = np.sin(np.pi * 2.0 * 50.0 * t)  # 50 Hz sinusoid signal
signal[np.logical_or(t < 0.45, t > 0.55)] = 0.0  # hard windowing
on_time = np.logical_and(t >= 0.45, t <= 0.55)
signal[on_time] *= np.hanning(on_time.sum())  # ramping
data[:, 100:-100] += np.tile(signal, n_epochs)  # add signal

raw = RawArray(data, info)
events = np.zeros((n_epochs, 3), dtype=int)
events[:, 0] = np.arange(n_epochs) * n_times
epochs = Epochs(
    raw,
    events,
    dict(sin50hz=0),
    tmin=0,
    tmax=n_times / sfreq,
    reject=dict(grad=4000),
    baseline=None,
)


x = epochs.get_data().mean(0)[None, ...]


sxx = _tf_decomp(
    x,
    1000,
    freqs,
    mode="morlet",
    mt_bandwidth=4,
    n_cycles=freqs / 4,
    decim=1,
    kw_cwt={},
    kw_mt={},
    n_jobs=10,
)

sxx = xr.DataArray(
    (sxx * np.conj(sxx)).real,
    name="power",
    dims=("trials", "roi", "freqs", "times"),
)


plt.plot(x[0, 0])
plt.plot(sxx[0, 0, 2])


sxx = (sxx - sxx.mean("times")) / sxx.std("times")


plt.plot(sxx[0, 0, 2])


def hilbert_spectra(
    data, fsample, freqs, bandwidth, n_jobs=1, verbose=False, kw_filter={}
):
    """
    Compute the Hilbert spectra of a 3D data array.

    Parameters:
    - data (xr.DataArray): Input data array with dimensions ("trials", "roi", "time").
    - fsample (float): Sampling frequency of the data.
    - freqs (array-like): Center frequencies for the spectral analysis.
    - bandwidth (float): Half-width of the frequency bands.
    - n_jobs (int, optional): Number of parallel jobs to run for filtering. Default is 1.
    - verbose (bool, optional): If True, print verbose messages during filtering. Default is False.
    - kw_filter (dict, optional): Additional keyword arguments for the `filter_data` function.

    Returns:
    - xr.DataArray: Hilbert spectra of the input data, with dimensions ("trials", "roi", "freqs", "times").

    Note:
    The input data is filtered into frequency bands centered at the specified frequencies with the given bandwidth.
    The Hilbert transform is then applied to obtain the analytic signal, and the squared magnitude of the analytic
    signal is computed to obtain the Hilbert spectra.

    The resulting DataArray has dimensions representing trials, regions of interest (ROIs), frequency bins, and time points.
    """

    from mne.filter import filter_data

    assert isinstance(data, xr.DataArray)

    dims = data.dims
    coords = data.coords
    attrs = data.attrs

    np.testing.assert_array_equal(dims, ("trials", "roi", "time"))

    lfreqs = np.clip(freqs - bandwidth, 0, np.inf)
    hfreqs = freqs + bandwidth

    bands = np.stack((lfreqs, hfreqs), axis=1)

    data_filtered = []
    for lf, hf in bands:
        data_filtered += [
            filter_data(
                data.values,
                fsample,
                lf,
                hf,
                n_jobs=n_jobs,
                **kw_filter,
                verbose=verbose
            )
        ]
    data_filtered = np.stack(data_filtered, axis=1)
    hilbert = scipy.signal.hilbert(data_filtered, axis=-1)
    sxx = hilbert * np.conj(hilbert)

    sxx = xr.DataArray(
        sxx.real,
        dims=("trials", "freqs", "roi", "times"),
        coords=(coords["trials"], freqs, coords["roi"], coords["time"]),
    ).transpose("trials", "roi", "freqs", "times")

    sxx.attrs = attrs

    return sxx


sxx = hilbert_spectra(xr.DataArray(x, dims=("trials", "roi", "time")), 1000, freqs, 4)


bandwidth = 4

lfreqs = np.clip(freqs - bandwidth, 0, np.inf)
hfreqs = freqs + bandwidth

bands = np.stack((lfreqs, hfreqs), axis=1)


POWER





_ROOT = os.path.expanduser("~/funcog/gda/")
metric = "coh"
monkey = "lucy"


sessions = get_dates(monkey)


evt_dt = return_evt_dt("cue", monkey)
stages = [[-0.5, -0.2], [0, 0.4], [0.5, 0.9], [0.9, 1.3], [1.1, 1.5]]
stage_labels = ["P", "S", "D1", "D2", "Dm"]


data_loader = loader(_ROOT=_ROOT)





# Window in which the data will be read
evt_dt = return_evt_dt("cue", monkey=monkey)
# Path to LFP data
raw_path = os.path.expanduser("~/funcog/gda/GrayLab/")
# Instantiate class
ses = session(
    raw_path=raw_path,
    monkey=monkey,
    date="141017",
    session=1,
    slvr_msmod=True,
    align_to="cue",
    evt_dt=evt_dt,
)

# Read LFP
ses.read_from_mat()
LFP = ses.filter_trials(trial_type=[1], behavioral_response=[1])

roi_channel = [f"{r} ({c})" for r, c in zip(LFP.roi.data, LFP.attrs["channels_labels"])]
LFP = LFP.assign_coords({"roi": roi_channel})

# Read SPIKES
ses.read_from_mat(load_spike_times=True)
SPIKES = ses.spike_times.sel(trials=LFP.trials)


SPIKES = SPIKES.assign_coords({"roi": roi_channel})


kw_loader = dict(
    session="141017", aligned_at="cue", channel_numbers=True, monkey=monkey, decim=5
)

POWER = data_loader.load_power(**kw_loader, trial_type=1, behavioral_response=1)


ZPOWER = (POWER - POWER.mean("times")) / POWER.std("times")


CRACKLES = ZPOWER >= 3


n_freqs = 10  # How many frequencies to use
freqs = np.linspace(3, 75, n_freqs)

decim = 5

sxx = _tf_decomp(
    LFP.isel(trials=slice(0, 50)),
    LFP.attrs["fsample"],
    freqs,
    mode="morlet",
    n_cycles=freqs / 8,
    decim=decim,
    kw_cwt={},
    kw_mt={},
    n_jobs=10,
)

sxx = xr.DataArray(
    (sxx * np.conj(sxx)).real,
    name="power",
    dims=("trials", "roi", "freqs", "times"),
    coords=(
        LFP.isel(trials=slice(0, 50)).trials.values,
        LFP.roi.values,
        freqs,
        LFP.time.values[::decim],
    ),
)


sxx = sxx.assign_coords({"roi": roi_channel})


z = sxx.sel(roi="a3 (106)", freqs=27)[10]
z = (z - z.mean("times")) / z.std("times")


LFP_FILTERED = filter_data(LFP.data, 1000, 25, 40, n_jobs=10, method="fir")
LFP_FILTERED = xr.DataArray(LFP_FILTERED, dims=LFP.dims, coords=LFP.coords)

H = (
    scipy.signal.hilbert(LFP_FILTERED.sel(roi="a3 (106)")[10])
    * np.conj(scipy.signal.hilbert(LFP_FILTERED.sel(roi="a3 (106)")[10]))
).real


plt.figure(figsize=(30, 4))
plt.plot(LFP_FILTERED.sel(roi="a3 (106)")[10][..., ::5] * 6000000000, c="b")
plt.title("A3 LFP FILTERED (25-40 Hz)", fontsize=20)
plt.figure(figsize=(30, 4))
plt.plot(H[::5] * 500000, c="k")
plt.title("Hilbert", fontsize=20)
plt.figure(figsize=(30, 4))
plt.plot(z * 500000, c="r")
plt.title("Multitaper", fontsize=20)
plt.figure(figsize=(30, 4))
plt.plot(ZPOWER.sel(roi="a3 (106)", freqs=27)[10] * 500000, c="g", label="MULTITAPER")
plt.title("Morlet", fontsize=20)
plt.savefig("test.png")


plt.figure(figsize=(30, 10))
plt.plot(ZPOWER.sel(roi="V1 (219)", freqs=27)[0])


plt.figure(figsize=(30, 10))
CRACKLES.sel(roi="V1 (219)").isel(trials=0).plot(cmap="binary")
# ( (LFP.sel(roi="V6A (183)")[0][..., ::5] *1e5 +  30 ) ).plot(lw=1) ;
((LFP_FILTERED.sel(roi="V1 (219)")[0][..., ::5] * 5e5 + 30)).plot(lw=1)
((ZPOWER.sel(roi="V1 (219)", freqs=35)[0] * 10 + 30)).plot(lw=3)
# ( (ZPOWER.sel(roi="a3 (106)", freqs=3)[0] * 10 + 30 ) ).plot(lw=3) ;
plt.xlim(1, 1.6)


plt.figure(figsize=(30, 10))
(1e6 * LFP.sel(roi="V1 (219)")[0]).plot()
(1e6 * LFP_FILTERED.sel(roi="V1 (219)")[0]).plot()
plt.ylabel("muV")


ZPOWER.sel(roi="V1 (219)", freqs=35)[0].plot()
plt.hlines(1, -0.5, 3, "g")
plt.hlines(2, -0.5, 3, "b")
plt.hlines(3, -0.5, 3, "r")


plt.figure(figsize=())
LFP.sel(roi="a3 (106)")[0][..., ::5].plot()


def triggered_avg(
    data=None,
    spikes=None,
    low_pass=None,
    high_pass=None,
    win_size=None,
    verbose=False,
    decim=None,
):

    n_trials, n_roi, n_times = data.shape
    roi = data.roi.data

    # High-pass filtered data
    data_hp = data.data
    # filter_data(
    #    data.data, data.fsample, l_freq=low_pass, h_freq=high_pass, verbose=verbose
    # )

    # Converts back to DataArray
    data_hp = xr.DataArray(data_hp, dims=data.dims, coords=data.coords)
    """
    data_hp = (data_hp - data_hp.mean(("trials", "time"))) / data_hp.std(
        ("trials", "time")
    )
    """

    if isinstance(decim, int):
        data_hp = data_hp[..., ::decim]
        n_times = data_hp.sizes["time"]

    # win_size = int(win_size * data.fsample)

    data_hp = data_hp.data.swapaxes(0, 1).reshape(n_roi, n_trials * n_times)
    spikes = spikes.data.reshape(n_roi, n_trials * n_times)

    def _for_roi(i):
        peaks = find_start_end(spikes[i]).mean(1).astype(int)
        snipets = np.zeros((len(peaks), 2 * win_size))
        for pidx, idx in enumerate(peaks):
            temp = data_hp[i, (idx - win_size) : (idx + win_size)]
            if len(temp) == 2 * win_size:
                snipets[pidx, :] = temp
        return (
            confidence_interval(snipets, axis=0, verbose=False).squeeze().T
        )  # snipets.mean(0)

    snipets = np.stack([_for_roi(i) for i in range(n_roi)])
    print(snipets.shape)
    times = np.linspace(-win_size, win_size, snipets.shape[1])
    snipets = xr.DataArray(
        snipets,
        dims=("roi", "times", "bounds"),
        coords=(
            roi,
            times,
            ["lower", "higher"],
        ),
    )

    return snipets


y = LFP * 1e6

CTA = []
nCTA = []

for freq in [27]:

    x = CRACKLES.sel(freqs=freq)

    out = triggered_avg(
        data=y,
        spikes=x,
        low_pass=1,
        high_pass=250,
        win_size=40,
        decim=5,
        verbose=False,
    )
    """
    out1 = triggered_avg(
        data=SPIKES_CV,
        spikes=np.logical_not(x),
        low_pass=1,
        high_pass=250,
        win_size=60,
        decim=5,
        verbose=False,
    )
    """
    CTA += [out]
    nCTA += [out1]


CTA = xr.concat(CTA, "freqs").assign_coords({"freqs": [27]})
nCTA = xr.concat(nCTA, "freqs").assign_coords({"freqs": [27]})


plt.figure(figsize=(20, 20))
unique_rois = np.unique(out.roi.data)
for pos, r in enumerate(out.roi[:100].data):
    plt.subplot(10, 10, pos + 1)
    CTA.sel(roi=r, freqs=27).median("bounds").plot()
    plt.fill_between(
        CTA.times,
        CTA.sel(roi=r, freqs=27).mean("bounds")
        - CTA.sel(roi=r, freqs=27, bounds="lower"),
        CTA.sel(roi=r, freqs=27).mean("bounds")
        + CTA.sel(roi=r, freqs=27, bounds="higher"),
        alpha=0.3,
    )
    plt.title(r)
plt.tight_layout()
plt.savefig("crackle_triggered_average.png")


roi = "V1 (206)"
plt.figure(figsize=(15, 5))
for pos, freq in enumerate(CRACKLES.freqs.data):
    plt.subplot(2, 5, pos + 1)
    CTA.sel(roi=roi, freqs=freq).plot()
    nCTA.sel(roi=roi, freqs=freq).plot()
    plt.title(f"{freq} Hz")
    plt.ylim(CTA.sel(roi=roi).min() - 5e-6, CTA.sel(roi=roi).max() + 5e-6)
plt.tight_layout()


kernel = np.hanning(100)


SPIKES_CV = scipy.signal.fftconvolve(SPIKES, kernel[None, None, :], axes=2, mode="same")


SPIKES_CV = xr.DataArray(SPIKES_CV, dims=SPIKES.dims, coords=SPIKES.coords)


SPIKES[10].sel(roi="V1 (206)").plot()
SPIKES_CV[10].sel(roi="V1 (206)").plot()


LFP.sel(roi="a3 ()")


LFP



