


import sys

sys.path.insert(1, "/home/vinicius/storage1/projects/GrayData-Analysis")


import os

import matplotlib
import matplotlib.pyplot as plt
import numpy as np
import pandas as pd
import scipy.stats as stats
import seaborn as sns
import xarray as xr
from frites.stats import confidence_interval
from frites.utils import parallel_func
from mne.stats import fdr_correction
from scipy.signal import fftconvolve
from tqdm import tqdm

from config import get_dates, return_delay_split
from GDa.flatmap.flatmap import flatmap
from GDa.graphics import plot
from GDa.loader import loader
from GDa.util import shuffle_along_axis
from utils import *





_ROOT = os.path.expanduser("~/funcog/gda/")


metric = "coh"
monkey = "ethyl"
ds = 1


early_cue, early_delay = return_delay_split(monkey, delay_type=ds)


sessions = get_dates(monkey)





import umap
from sklearn.cluster import KMeans
from sklearn.decomposition import NMF, PCA
from sklearn.manifold import TSNE
from sklearn.metrics import silhouette_score





def bootstrap(ts_stacked, n_trials, n_rois, n_boot):
    """
    Performs the bootstrap method on the given data.

    Parameters
    ----------
    n_boot : int
        The number of iterations for the bootstrap method
    ts_stacked : ndarray
        The time series data in stacked format
    n_trials : int
        The number of trials in the time series data
    n_rois : int
        The number of regions of interest in the time series data
    verbose : bool, optional
        Whether to print the iteration number, by default False

    Returns
    -------
    ndarray
        The bootstrapped confidence interval
    """

    ci = []
    for i in range(n_boot):
        ci += [
            np.take_along_axis(
                ts_stacked,
                np.asarray(
                    [np.random.choice(range(n_trials), n_trials) for _ in range(n_rois)]
                ),
                axis=-1,
            ).mean(-1)
        ]
    ci = np.stack(ci)
    return ci


def compute_median_rate(
    data: xr.DataArray,
    roi: str = None,
    thr: float = 3,
    stim_label: int = None,
    freqs: float = None,
    time_slice: slice = None,
    # freqs: float = None,
    n_boot: int = 100,
    n_jobs: int = 1,
    verbose: bool = False,
):
    """
    Calculates the median rate of the provided xarray DataArray, subject to optional parameters.

    Parameters:
    ----------
        data: xr.DataArray
            The input data for which the median rate is to be calculated.
        roi: str | None
            A string specifying the region of interest (ROI) to consider in the analysis.
            If None, all ROIs will be considered.
        thr: (float) | .95
            A float representing the quantile based threshold.
            Any values in 'data' less than this threshold will be set to zero.
        stim_label: int | None
            An int specifying a particular stimulus label to use in the analysis.
            If None, all stimuli will be considered.
        time_slice: slice | None
            A slice object specifying a range of times to consider in the analysis.
            If None, all times will be considered.
        freqs: float | None
            A float specifying a frequency range to use in the analysis.
            If None, all frequencies will be considered.
        n_boot: int | 100
            An int specifying the number of bootstrap resamples to use when calculating
            the median rate.
        verbose: bool | False
            When set to True, the tqdm library will be used to display a progress
            bar while the function is running.

    Returns:
    -------
        Tuple of two xarray.DataArray,
        where the first is the result of median rate calculation of the given data,
        and the second is the median rate calculated by shuffling the data along the first axis.

    """

    # Check coordinates of the DataArray
    np.testing.assert_array_equal(("roi", "freqs", "trials", "times"), data.dims)

    if isinstance(stim_label, int):
        # Get stimulus label from each trial
        stim_labels = data.stim
        # Select trials with the specific label
        idx_trials = stim_labels == stim_label
    else:
        # Otherwise get all trials
        idx_trials = [True] * data.sizes["trials"]

    data = (data - data.mean("times")) / data.std("times")

    if thr > 0:
        # Compute quantile based threshold
        # thr = data.quantile(thr, ("trials", "times"))
        # Apply threshold
        data = data >= thr
    else:
        data = data * (data >= 0)

    # Get time-series for specific trials, roi and time slice
    ts = data.sel(times=time_slice, roi=roi).isel(trials=idx_trials)

    if isinstance(freqs, (int, float)):
        freqs = [freqs]
    else:
        freqs = ts.freqs.data

    times = ts.times.data
    nfreqs, ntimes = len(freqs), len(times)

    def _for_freq(f):
        """
        Compute the bootstrapped confidence interval and surrogate time series data
        for a specific frequency band.

        Parameters:
        -----------
        f: float or int
            The specific frequency band for which to compute the confidence
            interval and surrogate time series data.

        Returns:
        --------
        ci: xr.DataArray
            The bootstrapped confidence interval, in the form of a xr.DataArray,
            with dimensions ('boot', 'times').
        surr: xr.DataArray
            The surrogate time series data, in the form of a xr.DataArray,
            with dimensions ('boot', 'times').
        """

        # Stack rois
        if "roi" in ts.dims:
            ts_stacked = ts.sel(freqs=f).stack(z=("trials", "roi")).data
        else:
            ts_stacked = ts.sel(freqs=f).data.T

        n_rois = ts_stacked.shape[0]
        n_trials = ts_stacked.shape[1]

        ci = bootstrap(ts_stacked, n_trials, n_rois, n_boot)

        surr = []
        for i in tqdm(range(n_boot)) if verbose else range(n_boot):
            surr += [shuffle_along_axis(ts_stacked, 0)]
        surr = np.stack(surr).mean(-1)
        ci = xr.DataArray(ci, dims=("boot", "times"), coords={"times": times})
        surr = xr.DataArray(surr, dims=("boot", "times"), coords={"times": times})

        return ci, surr

    # define the function to compute in parallel
    parallel, p_fun = parallel_func(
        _for_freq, n_jobs=n_jobs, verbose=verbose, total=nfreqs
    )
    # Compute the single trial coherence
    out = parallel(p_fun(f) for f in freqs)

    ci = [out[i][0] for i in range(nfreqs)]
    surr = [out[i][1] for i in range(nfreqs)]

    ci = xr.concat(ci, "freqs").assign_coords({"freqs": freqs})
    surr = xr.concat(surr, "freqs").assign_coords({"freqs": freqs})

    return ci, surr


def cluster_burst_prob(data, n_components, ksize=None, seed=0, n_jobs=1, verbose=False):
    """
    cluster_burst_prob - function to perform KMeans clustering and Non-negative matrix
    factorization (NMF) on input data with parallel computing.

    Parameters:
    data (xr.DataArray): input data with dimensions roi, freqs, boot, times
    n_components (int): number of clusters for KMeans and NMF
    seed (int, optional): seed for random number generator (default 0)
    n_jobs (int, optional): number of jobs for parallel computing (default 1)
    verbose (bool, optional): flag for verbose output (default False)

    Returns:
    W (xr.DataArray): data array for the features of KMeans
    H (xr.DataArray): data array for the components of NMF
    labels (xr.DataArray): data array for the labels of KMeans

    """
    np.testing.assert_array_equal(data.dims, ("roi", "freqs", "boot", "times"))

    rois, freqs, times = data.roi.data, data.freqs.data, data.times.data

    nfreqs = len(freqs)

    X = data.median("boot")

    def _for_freq(f):

        X_ = X.sel(freqs=f)

        # Perform KMeans clustering
        labels = (
            KMeans(n_clusters=n_components, random_state=seed, init="random")
            .fit(X_.data)
            .labels_
        )

        # NNTF
        nmf = NMF(
            n_components=n_components, init="random", random_state=seed, max_iter=10000
        )
        W = nmf.fit_transform(X_.data)
        H = nmf.components_

        times = X_.times.data.astype(np.float32)

        return W, H, labels

    # define the function to compute in parallel
    parallel, p_fun = parallel_func(
        _for_freq, n_jobs=n_jobs, verbose=verbose, total=nfreqs
    )
    # Compute the single trial coherence
    out = parallel(p_fun(f) for f in freqs)

    # Unpacking outputs
    W = np.stack([out[i][0] for i in range(nfreqs)], 1)
    H = np.stack([out[i][1] for i in range(nfreqs)], 1)
    labels = np.stack([out[i][2] for i in range(nfreqs)], 1)

    if isinstance(ksize, int):
        kernel = np.ones(ksize) / ksize
        H = fftconvolve(H, kernel[np.newaxis, np.newaxis, ...], mode="same", axes=2)

    # Convert to DataArray
    W = xr.DataArray(
        W, dims=("roi", "freqs", "components"), coords=dict(roi=rois, freqs=freqs)
    )

    H = xr.DataArray(
        H, dims=("components", "freqs", "times"), coords=dict(times=times, freqs=freqs)
    )

    labels = xr.DataArray(
        labels, dims=("roi", "freqs"), coords=dict(roi=rois, freqs=freqs)
    )

    return W, H, labels


reg_colors = dict(
    zip(
        [
            "motor",
            "parietal",
            "prefrontal",
            "somatosensory",
            "temporal",
            "visual",
            "auditory",
        ],
        ["r", "aqua", "b", "m", "goldenrod", "green", "brown"],
    )
)


stages = [[-0.5, -0.2], [0, 0.4], [0.5, 0.9], [0.9, 1.3], [1.1, 1.5]]
stage_labels = ["P", "S", "D1", "D2", "Dm"]





data_loader = loader(_ROOT=_ROOT)


kw_loader = dict(
    session="141024", aligned_at="cue", channel_numbers=False, monkey=monkey, decim=20
)

power_task = data_loader.load_power(**kw_loader, trial_type=1, behavioral_response=1)
power_fix = data_loader.load_power(**kw_loader, trial_type=2, behavioral_response=0)


def return_burst_prob(power, conditional=False, thr=0.95, verbose=False):
    """
    Computes the burst probability and surrogate burst probability
    for each region of interest (ROI) in the given power dataset.

    Parameters
    ----------
    power : xarray Dataset
        A multi-dimensional dataset containing the power values of
        the time-frequency representation of the time series.
    conditional : bool, optional
        Whether to compute the burst probability and surrogate burst
        probability separately for each stimulus, by default False
    thr : float, optional
        The threshold for burst detection, by default 0.95

    Returns
    -------
    tuple
        A tuple containing the burst probability and surrogate burst
        probability for each ROI, in the format (P_b, SP_b)
    """
    kw_args = dict(
        thr=thr,
        freqs=None,
        stim_label=None,
        time_slice=slice(-0.5, 2.0),
        n_boot=100,
        verbose=False,
        n_jobs=10,
    )

    trials, stim = power.trials.data, power.attrs["stim"]
    rois = np.unique(power.roi.values)

    def _for_roi():

        # Rate modulation
        P_b = []
        SP_b = []

        for roi in tqdm(rois) if verbose else rois:
            ci, surr = compute_median_rate(power, roi=roi, **kw_args)
            P_b += [ci]
            SP_b += [surr]

        P_b = xr.concat(P_b, "roi")
        P_b = P_b.assign_coords({"roi": rois})
        SP_b = xr.concat(SP_b, "roi")
        SP_b = SP_b.assign_coords({"roi": rois})

        return P_b, SP_b

    if not conditional:
        return _for_roi()
    else:
        # Stimulus dependent rate modulation
        P_b_stim = []
        SP_b_stim = []
        for stim in tqdm(range(1, 6)) if verbose else range(1, 6):
            kw_args["stim_label"] = stim
            P_b, SP_b = _for_roi()

            P_b_stim += [P_b]
            SP_b_stim += [SP_b]
        P_b_stim = xr.concat(P_b_stim, "stim")
        SP_b_stim = xr.concat(SP_b_stim, "stim")

        return P_b_stim, SP_b_stim


# Computes burst probability for task and fixation
P_b_task, SP_b_task = return_burst_prob(power_task, thr=3)
P_b_fix, SP_b_fix = return_burst_prob(power_fix, thr=3)


# Computes burst probability for task and fixation
P_b_task_stim, SP_b_task_stim = return_burst_prob(power_task, conditional=True, thr=3)


W_task, H_task, labels_task = cluster_burst_prob(
    P_b_task, 5, ksize=4, seed=0, n_jobs=10
)
W_fix, H_fix, labels_fix = cluster_burst_prob(P_b_fix, 5, ksize=3, seed=0, n_jobs=10)


for f in H_task.freqs.data:

    plt.figure(figsize=(15, 6))
    for i in range(5):

        ax = plt.subplot(2, 5, i + 1)

        values = W_task.sel(freqs=f, components=i)
        areas = [a.lower() for a in values.roi.data]
        fmap = flatmap(values.data, areas)

        # Only plot colorbar for last column
        fmap.plot(
            ax,
            ax_colorbar=None,
            cbar_title="Norm. entropy",
            alpha=0.6,
            vmin=0,
            vmax=0.1,
            colormap="Greys",
        )
        plt.title(f"factor {i + 1}")
    plt.suptitle(f"{f} Hz")
    # Factors
    for i in range(5, 10):

        ax = plt.subplot(2, 5, i + 1)

        plt.plot(H_task.times, H_task.sel(freqs=f, components=i - 5), color="b")
        [ax.spines[key].set_visible(False) for key in ["top", "right"]]
        plt.xlim(-0.5, 2)
        plt.xlabel("Time [s]")


plt.figure(figsize=(14, 6))

from brainconn.modularity import modularity_finetune_und_sign

X = H_task.stack(features=("components", "freqs")).T
A = np.corrcoef(X)
np.fill_diagonal(A, 0)

X = W_task.stack(features=("components", "freqs")).T
B = np.corrcoef(X)
np.fill_diagonal(B, 0)

features = [f"{el.data.tolist()[0]}-{int(el.data.tolist()[1])}" for el in X.features]

plt.subplot(1, 2, 1)
av, q = modularity_finetune_und_sign(A)
idx = np.argsort(av)
plt.imshow(
    A[np.ix_(idx, idx)],
    aspect="auto",
    origin="lower",
    vmin=-0.4,
    vmax=0.4,
    cmap="RdBu_r",
)


plt.xticks(range(len(features)), features, rotation=90)
plt.yticks(range(len(features)), features)

plt.subplot(1, 2, 2)
av, q = modularity_finetune_und_sign(B)
idx = np.argsort(av)
plt.imshow(
    B[np.ix_(idx, idx)],
    aspect="auto",
    origin="lower",
    vmin=-0.4,
    vmax=0.4,
    cmap="RdBu_r",
)

plt.xticks(range(len(features)), features, rotation=90)
plt.yticks(range(len(features)), features);


H_task = H_task.sel(components=[0, 3, 2, 4])



plt.figure(figsize=(6, 14))

from brainconn.modularity import modularity_finetune_und_sign

X = H_task.stack(features=("components", "freqs")).T
A = np.corrcoef(X)
np.fill_diagonal(A, 0)

X = W_task.stack(features=("components", "freqs")).T
B = np.corrcoef(X)
np.fill_diagonal(B, 0)

features = [f"{el.data.tolist()[0]}-{int(el.data.tolist()[1])}" for el in X.features]

plt.subplot(2, 1, 1)
av, q = modularity_finetune_und_sign(A)
idx = np.argsort(av)
plt.imshow(
    A[np.ix_(idx, idx)],
    aspect="auto",
    origin="lower",
    vmin=-0.4,
    vmax=0.4,
    cmap="RdBu_r",
)
plt.title("Temporal correlation")

plt.xticks(range(len(features)), features, rotation=90)
plt.yticks(range(len(features)), features)

plt.subplot(2, 1, 2)
av, q = modularity_finetune_und_sign(B)
idx = np.argsort(av)
plt.imshow(
    B[np.ix_(idx, idx)],
    aspect="auto",
    origin="lower",
    vmin=-0.4,
    vmax=0.4,
    cmap="RdBu_r",
)
plt.title("Spatial correlation")


plt.xticks(range(len(features)), features, rotation=90)
plt.yticks(range(len(features)), features);

plt.savefig("figures/final/factor_temp_spa_corr.png")


for f in H_task.freqs.data:
    plt.figure(figsize=(15, 6), dpi=600)
    for i in range(4):

        ax = plt.subplot(2, 4, i + 1)

        values = W_task.sel(freqs=f, components=i)
        areas = [a.lower() for a in values.roi.data]
        fmap = flatmap(values.data, areas)

        # Only plot colorbar for last column
        fmap.plot(
            ax,
            ax_colorbar=None,
            cbar_title="Norm. entropy",
            alpha=0.6,
            vmin=0,
            vmax=0.2,
            colormap="Greys",
        )
        plt.title(f"factor {i + 1}")
    # Factors
    for i in range(4, 8):

        ax = plt.subplot(2, 4, i + 1)

        plt.plot(H_task.times, H_task.sel(freqs=f, components=i - 4), color="b")
        [ax.spines[key].set_visible(False) for key in ["top", "right"]]
        plt.xlim(-0.5, 2)
        plt.xlabel("Time [s]")
    plt.savefig(f"figures/final/NMF_{monkey}_{int(f)}.pdf")


plt.figure(figsize=(6, 2))
z = power_task
z = (power_task - power_task.mean("times")) / power_task.std("times") >= 3
plt.imshow(
    z.sel(roi="V1", freqs=27, times=slice(0, 2)).isel(roi=-1),
    aspect="auto",
    origin="lower",
    cmap="binary",
)
plt.ylabel("trials", fontsize=12)
plt.xlabel("time", fontsize=12)


plt.figure(figsize=(6, 2), dpi=600)

plt.imshow(
    z.sel(freqs=27).isel(trials=slice(0, 5)).stack(obs=("trials", "times")),
    aspect="auto",
    origin="lower",
    cmap="binary",
)
plt.ylabel("channels", fontsize=12)
plt.xlabel("time", fontsize=12)


# Get the region name for each roi
areas_dict = get_areas()
regions = np.asarray([areas_dict[roi.lower()] for roi in P_b_task.roi.data])


idx = np.argsort(regions)


plt.figure(figsize=(10, 5.5), dpi=600)
ax = plt.subplot(111)
plot_rate_probability(
    P_b_task.median("boot").sel(freqs=27).isel(roi=idx),
    labels_task.sel(freqs=3),
    ax,
    vmax=0.05,
)
plt.xticks(fontsize=9)
plt.yticks(range(P_b_task.sizes["roi"]), P_b_task.roi.data[idx], fontsize=9)

plt.colorbar(extend="max")

plt.savefig(f"figures/final/pc_map_{monkey}.pdf")


kw_loader = dict(
    session="141024", aligned_at="cue", channel_numbers=False, monkey=monkey, decim=5
)

power_task = data_loader.load_power(**kw_loader, trial_type=1, behavioral_response=1)
power_fix = data_loader.load_power(**kw_loader, trial_type=2, behavioral_response=0)

z_power_fix = (power_fix - power_fix.mean("times")) / power_fix.std("times")
z_power_task = (power_task - power_task.mean("times")) / power_task.std("times")

zci_fix = (
    confidence_interval(z_power_fix.sum("roi"), axis=1)
    .squeeze()
    .sel(freqs=27, times=slice(-0.5, 2))
)
zci_task = (
    confidence_interval(z_power_task.sum("roi"), axis=1)
    .squeeze()
    .sel(freqs=27, times=slice(-0.5, 2))
)


plt.fill_between(
    zci_task.times, zci_task.isel(bound=0), zci_task.isel(bound=1), alpha=0.3, color="b"
)
zci_task.mean("bound").plot(color="b", label="task")

plt.fill_between(
    zci_fix.times,
    zci_fix.isel(bound=0),
    zci_fix.isel(bound=1),
    alpha=0.3,
    color="orange",
)
zci_fix.mean("bound").plot(color="orange", label="fixation")

plt.legend(frameon=False, fontsize=6)
plt.title("27 Hz band", fontsize=8)

plt.ylabel("Total activation", fontsize=8, labelpad=-1)
plt.xlabel("Time [s]", fontsize=8)
[axs5.spines[key].set_visible(False) for key in ["top", "right"]]





def plot_rate_probability(
    X, labels, ax, vmax=None, cmap="turbo", colors=["r", "b", "g", "m"]
):
    """
    Plot a rate probability heatmap of the data X, highlighting different regions in different colors.

    Parameters:
    - X (xarray.DataArray): The data array to be plotted. Should have dimensions ('roi', 'times')
    - labels (xarray.DataArray): An array of labels for each region of interest. Should have dimension 'roi'.
    - ax (matplotlib.axes._subplots.AxesSubplot): The axes object to use for the plot.
    - vmax (float, optional): The maximum value for the color scale. If None, it defaults to the maximum value of the data.
    - colors (list, optional): A list of color codes to use for the different labels. Default is ["r", "b", "g", "m"].

    Returns:
    - None
    """
    plt.sca(ax)

    rois, times = X.roi.data, X.times.data
    nrois, ntimes = len(rois), len(times)
    labels = np.asarray(labels.sel(roi=X.roi))

    idx = np.argsort(labels).data
    print(idx)

    plt.imshow(
        X.data[idx, :], aspect="auto", cmap=cmap, origin="lower", vmin=0, vmax=vmax
    )
    x_ticks_idx = ax.get_xticks()[1:-1].astype(int)

    tks = plt.yticks(range(nrois), rois[idx])
    # [tks[1][i].set_color(colors[labels[idx][i]]) for i in range(nrois)]
    plt.xlabel("Time [s]", fontsize=12)

    refs = np.asarray([np.abs(t - times).argmin() for t in [0, 0.5, 1.5]])
    plt.xticks(refs, [0, 0.5, 1.5])

    [ax.axvline(refs[i], -0.1, nrois - 1, color="k", ls="--") for i in range(3)]


def plot_embedding(W, labels, ax, names=True, colors=["r", "b", "g", "m"]):
    """
    Plot a 2D embedding of data W, highlighting different regions in different colors.

    Parameters:
    - W (np.ndarray): The data array to be plotted. Should have shape (num_roi, feature_dim)
    - labels (xarray.DataArray): An array of labels for each region of interest. Should have dimension 'roi'.
    - ax (matplotlib.axes._subplots.AxesSubplot): The axes object to use for the plot.
    - names (bool, optional): Whether to show the names of each point in the plot or not. Default is True
    - colors (list, optional): A list of color codes to use for the different labels. Default is ["r", "b", "g", "m"].

    Returns:
    - None
    """
    plt.sca(ax)

    labels = np.asarray(labels.sel(roi=W.roi)).data
    rois = W.roi.data
    nrois = len(rois)

    X_embedded = umap.UMAP(n_neighbors=5, min_dist=1, random_state=20).fit_transform(W)

    for i in range(len(X_embedded)):
        plt.scatter(X_embedded[i, 0], X_embedded[i, 1], color=colors[labels[i]])
    if names:
        for i in range(len(X_embedded)):
            plt.text(X_embedded[i, 0] + 0.1, X_embedded[i, 1] + 0.1, rois[i])
    plt.xticks([])
    plt.yticks([])
    [ax.spines[key].set_visible(False) for key in ax.spines.keys()]


import matplotlib
from matplotlib.patches import Rectangle

thr_task = power_task.quantile(0.9, ("trials", "times"))
raster_task = power_task >= thr_task

# v1ts = raster_task.sel(freqs=27, roi="V1").isel(roi=0)
v1ts = power_task.sel(freqs=27, roi="V1").isel(roi=0)
v1ts = (v1ts - v1ts.mean("times")) / v1ts.std("times")
v1ts = v1ts * (v1ts >= 0)
times = v1ts.times.data

fig = plt.figure(figsize=(8, 7), dpi=600)

gs0 = fig.add_gridspec(
    nrows=2,
    ncols=1,
    left=0.05,
    right=0.45,
    hspace=0.3,
    bottom=0.6,
    top=0.95,
    height_ratios=(1.0, 0.4),
)

gs1 = fig.add_gridspec(
    nrows=1,
    ncols=1,
    left=0.52,
    right=0.98,
    hspace=0.1,
    bottom=0.63,
    top=0.925,
)

gs2 = fig.add_gridspec(
    nrows=2,
    ncols=4,
    left=0.05,
    right=0.95,
    hspace=0.2,
    wspace=0.3,
    bottom=0.07,
    top=0.47,
)


axs0 = [plt.subplot(gs0[i]) for i in range(2)]

plt.sca(axs0[0])
for i in range(10):
    plt.step(times, 3 * v1ts.isel(trials=i) + 4.5 * i, color="b", lw=1)
    plt.text(3.1, 4.7 * i - 2, f"{10 - i}", fontsize=9)

plt.step(times, 3 * v1ts.isel(trials=i) - 20, color="b", lw=1)
plt.text(3.1, -21.5, "T", fontsize=9)
plt.text(1.1, -18, ".", fontsize=15)
plt.text(1.1, -10, ".", fontsize=15)
plt.text(1.1, -6, ".", fontsize=15)
# plt.axis("off")
plt.title("Activation time-series for V1 (236) at 27 Hz band", fontsize=10)
[axs0[0].spines[key].set_visible(False) for key in ["top", "right", "bottom"]]
plt.yticks([])
plt.xticks([])

plt.ylabel("Trials")

plt.sca(axs0[1])
v1ts.mean("trials").sel(times=slice(-0.5, 2)).plot(x="times")
[axs0[1].spines[key].set_visible(False) for key in ["top", "right"]]
plt.ylabel(r"$P_c[t]$", fontsize=10, labelpad=-8)
plt.xlabel("Time [s]", fontsize=10)
plt.title("")
trans = matplotlib.transforms.blended_transform_factory(
    axs0[1].transData, fig.transFigure
)
r = matplotlib.patches.Rectangle(
    xy=(-0.1, 0.605), width=0.2, height=0.35, transform=trans, fc="none", ec="r", lw=0.7
)
fig.add_artist(r)
plt.xlim(-0.5, 2)

axs1 = plt.subplot(gs1[0])
plt.sca(axs1)
plot_rate_probability(
    P_b_task.sel(freqs=27).median("boot"),
    labels_task.sel(freqs=3),
    axs1,
    vmax=0.05,
    cmap="turbo",
)
plt.xticks(fontsize=10)
plt.yticks(fontsize=8)
plt.xlabel("Time [s]", fontsize=10)
plt.title("Single-session clackle time-resolved probability", fontsize=10)

axs2 = [plt.subplot(gs2[i]) for i in range(8)]

# Factors
for i in range(4):

    values = W_task.sel(freqs=27, components=i)
    areas = [a.lower() for a in values.roi.data]
    fmap = flatmap(values.data, areas)

    # Only plot colorbar for last column
    fmap.plot(
        axs2[i],
        ax_colorbar=None,
        cbar_title="Norm. entropy",
        alpha=0.6,
        vmin=0,
        vmax=0.2,
        colormap="Greys",
    )
    plt.title(f"factor {i + 1}")
# Factors
for i in range(4, 8):
    plt.sca(axs2[i])
    plt.plot(H_task.times, H_task.sel(freqs=27, components=i - 4), color="b")
    [axs2[i].spines[key].set_visible(False) for key in ["top", "right"]]
    plt.xlim(-0.5, 2)
    plt.xlabel("Time [s]")


plot.add_panel_letters(
    fig,
    axes=[
        axs0[0],
        axs1,
        axs2[0],
        axs2[4],
        axs2[1],
        axs2[5],
        axs2[2],
        axs2[6],
        axs2[3],
        axs2[7],
    ],
    fontsize=12,
    xpos=[
        -0.1,
        -0.1,
        -0.0,
        -0.0,
        -0.0,
        -0.0,
        -0.0,
        -0.0,
        -0.0,
        -0.0,
    ],
    ypos=[0.93, 1.05, 1.0, 1.1, 1.0, 1.1, 1.0, 1.1, 1.0, 1.1],
)

bg = plot.Background(visible=False)

plt.savefig("figures/n2/figure5.pdf")


m = P_b_task.median("boot")
lb = P_b_task_stim.quantile(0.05, "boot")
ub = P_b_task_stim.quantile(0.95, "boot")


RMIt = (m < lb).astype(int) + (m > ub).astype(int)


RMI = []
for pos, (t_0, t_1) in enumerate(stages):
    RMI += [RMIt.sel(times=slice(t_0, t_1)).mean("times").mean("stim")]
RMI = xr.concat(RMI, "times")


regions = np.array([get_areas()[roi.lower()] for roi in RMI.roi.data])
idx = np.argsort(regions)


plt.figure(figsize=(6, 10))
titles = ["P", "S", "D1", "D2", "Dm"]
for pos, (t_0, t_1) in enumerate(stages):

    plt.subplot(5, 1, pos + 1)

    plt.imshow(
        RMI.isel(times=pos).T[:, idx],
        origin="lower",
        cmap="turbo",
        aspect="auto",
    )
    plt.yticks(range(10), m.freqs.data)
    tks = plt.xticks(range(m.sizes["roi"]), m.roi.data[idx], rotation=90)
    [tks[1][i].set_color(reg_colors[r]) for i, r in enumerate(regions[idx])]
    plt.title(f"{titles[pos]}", fontsize=15)
    plt.colorbar()
plt.tight_layout()


idx = np.argsort(regions)


m = P_b_task.median("boot")
lb = P_b_fix.quantile(0.05, "boot")
ub = P_b_fix.quantile(0.95, "boot")

RMIt = -(m < lb).astype(int) + (m > ub).astype(int)


RMI = []
for pos, (t_0, t_1) in enumerate(stages):
    RMI += [RMIt.sel(times=slice(t_0, t_1)).mean("times")]
RMI = xr.concat(RMI, "times")


plt.figure(figsize=(6, 10), dpi=600)
titles = ["P", "S", "D1", "D2", "Dm"]
for pos, (t_0, t_1) in enumerate(stages):

    plt.subplot(5, 1, pos + 1)

    plt.imshow(
        RMI.isel(times=pos).T[:, idx],
        vmin=-0.6,
        vmax=0.6,
        origin="lower",
        cmap="RdBu_r",
    )
    plt.yticks(range(10), m.freqs.data)
    tks = plt.xticks(range(m.sizes["roi"]), m.roi.data[idx], rotation=90)
    [tks[1][i].set_color(reg_colors[r]) for i, r in enumerate(regions[idx])]
    plt.title(f"{titles[pos]}", fontsize=15)
    plt.colorbar()


import numba as nb


def return_crossband_cc(burst_probs):
    """
    Calculate cross-frequency correlation coefficient between all pairs of ROIs,
    at different frequency bands of a given burst_probs.

    Parameters
    ----------
    burst_probs : xr.DataArray
        A 4D array with dimensions ("roi", "freqs", "boot", "times").
        Should contain probability of bursts of activity at different frequency bands,
        for different regions of interest (ROIs) and different time points.

    Returns
    -------
    mat : xr.DataArray
        A 3D array with dimensions ("sources", "targets", "freqs"),
        containing the cross-frequency correlation coefficient between all pairs of ROIs.
    """
    np.testing.assert_array_equal(burst_probs.dims, ("roi", "freqs", "boot", "times"))

    nrois, nfreqs, nboot, ntimes = [
        burst_probs.sizes[key] for key in burst_probs.sizes.keys()
    ]

    times, freqs, rois = [
        burst_probs.coords[key].data for key in burst_probs.coords.keys()
    ]

    freqs = freqs.astype(int)

    # Pairs of frequencies
    pairs = np.stack(np.triu_indices(nfreqs, k=1), 1)
    # Number of pairs
    n_xf = len(pairs)

    burst_probs = burst_probs.median("boot").data

    @nb.njit
    def _for_freq():
        mat = np.zeros((nrois, nrois, n_xf))
        nf = 0
        for i, j in pairs:
            mat[..., nf] = np.corrcoef(
                burst_probs[:, i],
                burst_probs[:, j],
            )[0:nrois, nrois : 2 * nrois]
            nf = nf + 1
        return mat

    mat = _for_freq()

    # Cross-frequency coordinates
    xf = [f"{freqs[i]}-{freqs[j]}" for i, j in pairs]

    mat = xr.DataArray(
        mat, dims=("sources", "targets", "freqs"), coords=(rois, rois, xf)
    )
    return mat


mat = [return_crossband_cc(P_b_task.isel(boot=[i])) for i in tqdm(range(100))]


mat_fix = [return_crossband_cc(P_b_fix.isel(boot=[i])) for i in tqdm(range(100))]


mat = xr.concat(mat, "boot")


mat_fix = xr.concat(mat_fix, "boot")


_, pvals = stats.ttest_ind(mat_fix, mat, axis=0)


out = mat.median("boot") * (pvals <= 0.0001)
out = (out + out.transpose("targets", "sources", "freqs")) / 2





data_loader = loader(_ROOT=_ROOT)


P_b_task = []
P_b_fix = []
P_b_stim = []

RMI, RSI = [], []

for session in tqdm(sessions):
    temp_task = data_loader.load_burst_prob(
        session=session,
        trial_type=1,
        aligned_at="cue",
        monkey=monkey,
        conditional=False,
        thr=3)

    temp_fix = data_loader.load_burst_prob(
        session=session,
        trial_type=2,
        aligned_at="cue",
        monkey=monkey,
        conditional=False,
        thr=3,
    )

    temp_stim = data_loader.load_burst_prob(
        session=session,
        trial_type=1,
        aligned_at="cue",
        monkey=monkey,
        conditional=True,
        thr=3.0,
    )

    P_b_task += [temp_task]
    P_b_fix += [temp_fix]
    P_b_stim += [temp_stim]

    # Rate modulation index
    # enh = temp_task.median("boot") >= temp_fix.quantile(0.95, "boot")
    # sup = temp_task.median("boot") <= temp_fix.quantile(0.05, "boot")
    # RMI += [(enh.astype(int) - sup.astype(int))]

    # Rate selectivity index
    # enh = temp_task.median("boot") <= temp_stim.quantile(0.05, "boot")
    # sup = temp_task.median("boot") >= temp_stim.quantile(0.95, "boot")
    # RSI += [(enh + sup).mean("stim")]


P_b_task = node_xr_remove_sca(data_loader.apply_min_rois(P_b_task, min_rois=10))
P_b_fix = node_xr_remove_sca(data_loader.apply_min_rois(P_b_fix, min_rois=10))
#RMI = node_xr_remove_sca(data_loader.apply_min_rois(RMI, min_rois=10))
#RSI = node_xr_remove_sca(data_loader.apply_min_rois(RSI, min_rois=10))


# Get the region name for each roi
areas_dict = get_areas()
regions = np.asarray([areas_dict[roi.lower()] for roi in P_b_task.roi.data])


bands = [[0, 6], [6, 14], [14, 26], [26, 42], [42, 80]]


Pb, Pbfix, rmi, rsi = [], [], [], []
for fl, fh in bands:
    #rmi += [RMI.sel(freqs=slice(fl, fh)).mean("freqs")]
    #rsi += [RSI.sel(freqs=slice(fl, fh)).mean("freqs")]
    Pb += [P_b_task.sel(freqs=slice(fl, fh)).mean("freqs")]
    Pbfix += [P_b_fix.sel(freqs=slice(fl, fh)).mean("freqs")]


Pb = xr.concat(Pb, "freqs").transpose(*P_b_task.dims)
Pbfix = xr.concat(Pbfix, "freqs").transpose(*P_b_fix.dims)
#rmi = xr.concat(rmi, "freqs").transpose(*RMI.dims)
#rsi = xr.concat(rsi, "freqs").transpose(*RSI.dims)


W_task, H_task, labels_task = cluster_burst_prob(
    Pb, 4, ksize=None, seed=0, n_jobs=10, verbose=False
)

W_fix, H_fix, labels_fix = cluster_burst_prob(
    Pbfix, 4, ksize=None, seed=0, n_jobs=10, verbose=False
)


import matplotlib

norm = matplotlib.colors.Normalize(vmin=0, vmax=3)
cmap = matplotlib.cm.get_cmap("jet")
colors = [cmap(norm(val)) for val in range(4)]


band_names = ["theta", "alpha", "beta", "high-beta", "gamma"]


import matplotlib
from matplotlib.patches import Rectangle

freqs = H_task.freqs.data
colors = np.asarray(["blue", "orange", "green", "red"])

fig = plt.figure(figsize=(8, 5), dpi=600)

gs0 = fig.add_gridspec(
    nrows=1,
    ncols=5,
    left=0.05,
    right=0.97,
    hspace=0.2,
    wspace=0.1,
    bottom=0.7,
    top=0.92,
)

gs1 = fig.add_gridspec(nrows=1, ncols=5, left=0.05, right=0.95, bottom=0.32, top=0.57)

gs2 = fig.add_gridspec(
    nrows=1,
    ncols=6,
    left=0.05,
    right=0.99,
    bottom=0.01,
    top=0.26,
    width_ratios=[1] * 5 + [0.05],
)

axs0 = [plt.subplot(gs0[i]) for i in range(5)]

for f in range(5):
    plt.sca(axs0[f])
    [
        H_task.sel(freqs=freqs[f], components=i).plot(lw=1, label=f"factor {i + 1}")
        for i in range(4)
    ]
    plt.xlim(-0.5, 2)
    plt.xlabel("Time [s]", fontsize=10)
    [axs0[f].spines[key].set_visible(False) for key in ["top", "right"]]
    plt.xticks(fontsize=10)
    plt.yticks(fontsize=10)
    plt.title(f"{band_names[f]}", fontsize=10, pad=0)
    if f == 0:
        plt.ylabel(r"$P_c[t]$", fontsize=10, labelpad=-7)
    else:
        plt.setp(axs0[f].get_yticklabels(), visible=False)
    plt.ylim(-0.01, 1)
    plt.locator_params(axis="y", nbins=2)

axs1 = [plt.subplot(gs1[i]) for i in range(5)]

for f in range(5):
    values = (W_task.sel(freqs=freqs[f]).argmax("components")).astype(int)
    areas = [a.lower() for a in values.roi.data]
    fmap = flatmap(values.data, areas)

    # Only plot colorbar for last column
    fmap.plot(
        axs1[f],
        ax_colorbar=None,
        cbar_title=None,
        alpha=0.4,
        vmin=0,
        vmax=3,
        colormap=None,
        colors=colors[values],
    )

axs2 = [plt.subplot(gs2[i]) for i in range(6)]

for f in range(5):
    normW = (
        W_task.sel(freqs=freqs[f]) / W_task.sel(freqs=freqs[f]).sum("components")
        + 1e-100
    )
    values = 1 + (normW * np.log(normW)).sum("components") / np.log(4)
    areas = [a.lower() for a in values.roi.data]
    fmap = flatmap(values.data, areas)

    ax_colorbar = None
    cbar_title = None
    if f == 4:
        ax_colorbar = axs2[-1]
        cbar_title = "exclusivity"
    # Only plot colorbar for last column
    fmap.plot(
        axs2[f],
        ax_colorbar=ax_colorbar,
        cbar_title="",
        alpha=0.6,
        vmin=0,
        vmax=0.4,
        colormap="Greys",
    )


plot.add_panel_letters(
    fig, axs0 + axs1 + axs2, fontsize=12, xpos=[-0.1] * 15, ypos=[1.1] * 5 + [1.0] * 10
)

bg = plot.Background(visible=False)

plt.savefig("figures/n2/figure6.pdf")


# Get the region name for each roi
areas_dict = get_areas()
roi_tpow = [roi for roi in P_b_fix.roi.data if roi not in ["a24D", "a11"]]
regions = np.asarray(
    [areas_dict[roi.lower()] for roi in P_b_fix.roi.data if roi not in ["a24D", "a11"]]
)
idx = np.argsort(regions)


RSI_ = RSI * (RSI >= 0.1)
RSI_ = RSI_.sel(roi=roi_tpow)


fig = plt.figure(figsize=(7, 6), dpi=600)

gs0 = fig.add_gridspec(
    nrows=2,
    ncols=1,
    left=0.05,
    right=0.97,
    hspace=0.4,
    bottom=0.11,
    top=0.96,
)

axs0 = [plt.subplot(gs0[i]) for i in range(2)]

plt.sca(axs0[0])
plt.imshow(
    RSI_.sel(times=slice(0.5, 0.9), roi=roi_tpow).mean("times").T[:, idx],
    cmap="turbo",
    origin="lower",
    vmax=0.3,
    vmin=0.1,
    aspect="auto",
)
tks = plt.xticks(range(len(RSI_.roi)), RSI_.roi.data[idx], rotation=90, fontsize=10)
[tks[1][i].set_color(reg_colors[r]) for i, r in enumerate(regions[idx])]
plt.colorbar()
plt.title("D1", fontsize=10)

plt.sca(axs0[1])
plt.imshow(
    RSI_.sel(times=slice(0.9, 1.3)).mean("times").T[:, idx],
    cmap="turbo",
    origin="lower",
    vmax=0.3,
    vmin=0.1,
    aspect="auto",
)
tks = plt.xticks(range(len(RSI_.roi)), RSI_.roi.data[idx], rotation=90, fontsize=10)
[tks[1][i].set_color(reg_colors[r]) for i, r in enumerate(regions[idx])]
plt.colorbar()
plt.title("D2", fontsize=10)

bg = plot.Background(visible=True)

plot.add_panel_letters(fig, axs0, fontsize=12, xpos=[-0.0] * 2, ypos=[1.02] * 2)

plt.savefig("figures/n2/figure6_rsi.png")





@numba.njit
def _histogram(x, bins):
    return np.histogram(x, bins=np.linspace(-3, 3, 20))[0]


def compute_power_pval(power_task, power_fix, stages):

    freqs = power_fix.freqs.data

    tvals = []
    pvals = []
    for t0, t1 in stages:
        t, p = stats.ttest_ind(
            power_fix.sel(times=slice(t0, t1)).mean("times"),
            power_task.sel(times=slice(t0, t1)).mean("times"),
            axis=2,
        )
        tvals += [t]
        pvals += [p]

    pvals, _ = fdr_correction(np.stack(pvals, -1), alpha=0.001)

    pvals = xr.DataArray(
        pvals,
        dims=("roi", "freqs", "times"),
        coords=(power_fix.roi, freqs, stage_labels),
    )

    tvals = xr.DataArray(
        np.stack(tvals, 2),
        dims=("roi", "freqs", "times"),
        coords=(power_fix.roi, freqs, stage_labels),
    )

    return tvals * pvals


def compute_crackle_pval(raster_task, raster_fix, stages):

    freqs = power_fix.freqs.data

    pvals = []
    for i in range(raster_task.sizes["times"]):
        _, temp = stats.kruskal(
            raster_fix.isel(times=i),
            raster_task.isel(times=i),
            axis=2,
        )
        pvals += [temp]

    pvals, _ = fdr_correction(np.stack(pvals, -1), alpha=0.001)
    pvals = xr.DataArray(
        pvals,
        dims=("roi", "freqs", "times"),
        coords=(raster_task.roi, freqs, stage_labels),
    )

    return pvals


def plot_tile_maps(values, regions, vmin=0, vmax=0.8, cmap="viridis"):
    idx = np.argsort(regions)

    for i in range(values.sizes["times"]):

        plt.subplot(1, len(stages), i + 1)

        plt.imshow(
            values.isel(times=i)[idx],
            aspect="auto",
            origin="lower",
            cmap=cmap,
            vmin=vmin,
            vmax=vmax,
        )

        if i == 0:
            tks = plt.yticks(range(len(values.roi)), values.roi.data[idx])
            [tks[1][j].set_color(colors[r]) for j, r in enumerate(regions[idx])]
        else:
            plt.yticks([])

        plt.xticks(range(len(freqs)), values.freqs.data.astype(int), rotation=90)
        plt.xlabel("Hz")
        plt.title(f"{values.times[i].data}")


def signal_entropy(power):

    bins = np.linspace(-3, 3, 20)
    nbins = len(bins)

    counts = np.apply_along_axis(_histogram, -1, power, bins=bins)

    pk = counts / counts.sum(-1)[..., np.newaxis]

    H = stats.entropy(pk, qk=None, base=None, axis=-1) / np.log(nbins)
    H = xr.DataArray(
        H,
        dims=("roi", "freqs", "trials"),
        coords=(power.roi, power.freqs, power.trials),
    )

    return H


def compute_time_series_cv(data, nbins=10):
    """
    Compute the coefficient of variation (CV) of a time series.

    The CV is defined as the standard deviation divided by the mean of the time series. This function also computes a confidence interval for the CV at a specified level.

    Parameters
    ----------
    data : xarray.DataArray
        The time series data. It should have dimensions 'roi', 'trials', and 'times'.

    Returns
    -------
    cv : xarray.DataArray
        The coefficient of variation of the time series data. It has dimensions 'roi', 'trials', and 'times'.
    """
    cv = signal_entropy(data)  # data.std("times") / data.mean("times")
    return confidence_interval(cv, cis=95, axis=2, n_boots=1000, verbose=False)


def plot_tile_maps(values, regions, vmin=0, vmax=0.8, cmap="viridis"):
    idx = np.argsort(regions)

    for i in range(values.sizes["times"]):

        plt.subplot(1, len(stages), i + 1)

        plt.imshow(
            values.isel(times=i)[idx],
            aspect="auto",
            origin="lower",
            cmap=cmap,
            vmin=vmin,
            vmax=vmax,
        )

        if i == 0:
            tks = plt.yticks(range(len(values.roi)), values.roi.data[idx])
            [tks[1][j].set_color(colors[r]) for j, r in enumerate(regions[idx])]
        else:
            plt.yticks([])

        plt.xticks(range(len(freqs)), values.freqs.data.astype(int), rotation=90)
        plt.xlabel("Hz")
        plt.title(f"{values.times[i].data}")


def plot_tile_map(ax, values, regions, time, vmin=0, vmax=0.8, cmap="viridis"):
    plt.sca(ax)
    idx = np.argsort(regions)

    freqs = values.freqs

    plt.imshow(
        values.isel(times=time)[idx],
        aspect="auto",
        origin="lower",
        cmap=cmap,
        vmin=vmin,
        vmax=vmax,
    )

    if time == 0:
        tks = plt.yticks(range(len(values.roi)), values.roi.data[idx], fontsize=6)
        [tks[1][j].set_color(colors[r]) for j, r in enumerate(regions[idx])]
    else:
        plt.yticks([])

    freq_ticks = ["", "11", "", "27", "", "43", "", "59", "", "75"]

    plt.xticks(range(len(freqs)), freq_ticks, rotation=90, fontsize=5)
    plt.xlabel("Hz", fontsize=6)
    plt.title(f"{values.times[time].data}", fontsize=8)

    ax.grid(which="minor", color="grey", linestyle="-", linewidth=2)


power = []
power_pval = []
crk_pval = []
CC_H_Pc = []
power_sig = []


def xr_w_score(data):
    return (data - data.mean("times")) / data.std("times")


def compute_for_session(session):

    kw_loader = dict(aligned_at="cue", channel_numbers=False, monkey=monkey)

    power_task = data_loader.load_power(
        **kw_loader, trial_type=1, behavioral_response=1, session=session, decim=5
    )

    power_fix = data_loader.load_power(
        **kw_loader, trial_type=2, behavioral_response=0, session=session, decim=5
    )

    freqs = power_task.freqs.data

    power_task = node_xr_remove_sca(power_task)
    power_fix = node_xr_remove_sca(power_fix)

    z_power_task = xr_w_score(power_task)
    z_power_fix = xr_w_score(power_fix)

    thr_fix = 3  # power_fix.quantile(0.9, ("trials", "times"))
    thr_task = 3  # power_task.quantile(0.9, ("trials", "times"))

    raster_fix = []
    raster_task = []
    power_task_mean = []

    for t0, t1 in stages:
        raster_fix += [(z_power_fix >= thr_fix).sel(times=slice(t0, t1)).mean("times")]
        raster_task += [
            (z_power_task >= thr_task).sel(times=slice(t0, t1)).mean("times")
        ]
        power_task_mean += [
            power_task.sel(times=slice(t0, t1)).mean(("times", "trials"))
        ]

    raster_task = xr.concat(raster_task, "times").transpose(*power_task.dims)
    raster_fix = xr.concat(raster_fix, "times").transpose(*power_task.dims)

    power_pval = compute_power_pval(z_power_task, z_power_fix, stages)
    crk_pval = compute_crackle_pval(raster_task, raster_fix, stages)

    power_task_mean = xr.concat(power_task_mean, "times").assign_coords(
        {"times": crk_pval.times}
    )

    power_sig = (power_task_mean * crk_pval).to_dataframe("power").reset_index()
    power_sig = power_sig.loc[power_sig.power > 0]
    power_sig["freqs"] = power_sig["freqs"].astype(int)

    cv_task = compute_time_series_cv(xr_w_score(power_task)).squeeze()

    ccs = np.zeros((raster_task.sizes["times"], raster_task.sizes["freqs"]))
    for fi, f in enumerate(raster_task.freqs.data):
        for it, t in enumerate(raster_task.times.data):
            x = cv_task.sel(freqs=f).median("bound")
            y = raster_task.mean("trials").sel(freqs=f, times=it)
            ccs[it, fi] = np.corrcoef(x, y)[0, 1]
    CC_H_Pc = ccs

    power = xr.concat(
        [
            power_task.sel(times=slice(t0, t1)).mean(("times", "trials"))
            for t0, t1 in stages
        ],
        "times",
    )

    ##########################################################################################
    rois = cv_task.roi.data
    areas_dict = get_areas()
    regions = np.asarray([areas_dict[roi.lower()] for roi in rois])
    unique_regions = np.unique(regions)

    x = cv_task.median("bound")
    y = raster_task.mean("trials")

    region2idx = dict(
        motor=0,
        parietal=1,
        prefrontal=2,
        somatosensory=3,
        temporal=4,
        visual=5,
        auditory=6,
    )

    CC_H_Pc_reg = np.zeros((7, 5, 10))

    for fi, freq in enumerate(freqs):
        for t in range(5):
            for ur in unique_regions:
                idx = regions == ur
                CC_H_Pc_reg[region2idx[ur], t, fi] = np.corrcoef(
                    x[idx, fi], y[idx, fi, t]
                )[0, 1]

    return (
        power,
        power_pval,
        crk_pval,
        power_sig,
        CC_H_Pc,
        cv_task,
        raster_task,
        CC_H_Pc_reg,
    )


def compute_for_sessions():

    # define the function to compute in parallel
    parallel, p_fun = parallel_func(
        compute_for_session, n_jobs=20, verbose=True, total=len(sessions)
    )
    # Compute the single trial coherence
    out = parallel(p_fun(session) for session in sessions)

    power = [out[i][0] for i in range(len(sessions))]
    power_pval = [out[i][1] for i in range(len(sessions))]
    crk_pval = [out[i][2] for i in range(len(sessions))]
    power_sig = [out[i][3] for i in range(len(sessions))]
    CC_H_Pc = [out[i][4] for i in range(len(sessions))]
    cv_task = [out[i][5] for i in range(len(sessions))]
    raster_task = [out[i][6] for i in range(len(sessions))]
    CC_H_Pc_reg = [out[i][7] for i in range(len(sessions))]

    return (
        power,
        power_pval,
        crk_pval,
        power_sig,
        CC_H_Pc,
        cv_task,
        raster_task,
        CC_H_Pc_reg,
    )


(
    power,
    power_pval,
    crk_pval,
    power_sig,
    CC_H_Pc,
    cv_task,
    raster_task,
    CC_H_Pc_reg,
) = compute_for_sessions()


power = data_loader.apply_min_rois(power, 10)
power_pval = data_loader.apply_min_rois(power_pval, 10)
crk_pval = data_loader.apply_min_rois(crk_pval, 10)


power_pval = node_xr_remove_sca(power_pval)
crk_pval = node_xr_remove_sca(crk_pval)


kw_loader = dict(
    session="141024", aligned_at="cue", channel_numbers=False, monkey=monkey, decim=5
)

power_task = data_loader.load_power(**kw_loader, trial_type=1, behavioral_response=1)
power_fix = data_loader.load_power(**kw_loader, trial_type=2, behavioral_response=0)

z_power_fix = (power_fix - power_fix.mean("times")) / power_fix.std("times")
z_power_task = (power_task - power_task.mean("times")) / power_task.std("times")

zci_fix = (
    confidence_interval(z_power_fix.sum("roi"), axis=1)
    .squeeze()
    .sel(freqs=27, times=slice(-0.5, 2))
)
zci_task = (
    confidence_interval(z_power_task.sum("roi"), axis=1)
    .squeeze()
    .sel(freqs=27, times=slice(-0.5, 2))
)


# Get the region name for each roi
areas_dict = get_areas()
regions = np.asarray([areas_dict[roi.lower()] for roi in power_pval.roi.data])


colors = dict(
    zip(
        [
            "motor",
            "parietal",
            "prefrontal",
            "somatosensory",
            "temporal",
            "visual",
            "auditory",
        ],
        ["r", "aqua", "b", "m", "goldenrod", "green", "brown"],
    )
)


fig = plt.figure(figsize=(8.0, 10.0), dpi=600)

gs0 = fig.add_gridspec(
    nrows=2,
    ncols=1,
    left=0.07,
    right=0.40,
    hspace=0.3,
    bottom=0.67,
    top=0.97,
)

gs0cb = fig.add_gridspec(
    nrows=1,
    ncols=1,
    left=0.41,
    right=0.42,
    bottom=0.67,
    top=0.97,
)


gs5 = fig.add_gridspec(
    nrows=1,
    ncols=1,
    left=0.07,
    right=0.42,
    hspace=0.1,
    bottom=0.43,
    top=0.60,
)

gs1 = fig.add_gridspec(
    nrows=1,
    ncols=6,
    left=0.53,
    right=0.92,
    wspace=0.2,
    bottom=0.67,
    top=0.97,
    width_ratios=[0.8, 0.8, 0.8, 0.8, 0.8, 0.1],
)

gs2 = fig.add_gridspec(
    nrows=1,
    ncols=1,
    left=0.5,
    right=0.95,
    bottom=0.4,
    top=0.95,
)

gs3 = fig.add_gridspec(
    nrows=1,
    ncols=1,
    left=0.53,
    right=0.92,
    hspace=0.1,
    bottom=0.43,
    top=0.60,
)

gs3cb = fig.add_gridspec(
    nrows=1,
    ncols=1,
    left=0.93,
    right=0.94,
    hspace=0.1,
    bottom=0.43,
    top=0.60,
)

gs4 = fig.add_gridspec(
    nrows=2,
    ncols=4,
    left=0.05,
    right=0.95,
    hspace=0.2,
    wspace=0.3,
    bottom=0.05,
    top=0.35,
)


axs0 = [plt.subplot(gs0[i]) for i in range(2)]
axs0cb = plt.subplot(gs0cb[0])
axs1 = [plt.subplot(gs1[i]) for i in range(6)]
axs3 = plt.subplot(gs3[0])
axs3cb = plt.subplot(gs3cb[0])
axs4 = [plt.subplot(gs4[i]) for i in range(8)]
axs5 = plt.subplot(gs5[0])

######################################################## CRACKLE TRAINS ########################################################

kw_loader = dict(
    session="141024", aligned_at="cue", channel_numbers=False, monkey=monkey
)

power_task = data_loader.load_power(
    **kw_loader, trial_type=1, behavioral_response=1, decim=5
)
power_fix = data_loader.load_power(
    **kw_loader, trial_type=2, behavioral_response=0, decim=5
)

thr_task = power_task.quantile(0.7, ("times", "trials"))
thr_fix = power_fix.quantile(0.7, ("times", "trials"))

z_power_task = xr_w_score(power_task)
z_power_fix = xr_w_score(power_fix)
tidx = [np.abs(z_power_fix.times.data - t).argmin() for t in [0, 0.5, 1.5]]


plt.sca(axs0[0])
plt.imshow(
    z_power_task.sel(freqs=27, times=slice(-0.5, 2)).isel(trials=200),
    aspect="auto",
    cmap="jet",
    origin="lower",
    vmin=0,
    vmax=5,
)
plt.title("Task", fontsize=8)
plt.xticks(tidx, [0, 0.5, 1.5], fontsize=8)
plt.yticks(fontsize=8)
plt.ylabel("Channels", fontsize=8, labelpad=-1)
# plt.xlabel("Time [s]", fontsize=8)
[plt.vlines(tidx[i], 0, 104, color="w") for i in range(len(tidx))]
plt.setp(axs0[0].get_xticklabels(), visible=False)

plt.sca(axs0[1])
plt.imshow(
    z_power_fix.sel(freqs=27, times=slice(-0.5, 2)).isel(trials=0),
    aspect="auto",
    cmap="jet",
    origin="lower",
    vmin=0,
    vmax=5,
)
plt.title("Fixation", fontsize=8)
plt.ylabel("Channels", fontsize=8, labelpad=-1)
plt.xlabel("Time [s]", fontsize=8)
plt.xticks(tidx, [0, 0.5, 1.5], fontsize=8)
plt.yticks(fontsize=8)
[plt.vlines(tidx[i], 0, 104, color="w") for i in range(len(tidx))]

norm = matplotlib.colors.Normalize(vmin=0, vmax=5)
cmap = matplotlib.cm.get_cmap("jet")


cbar = plt.colorbar(
    mappable=plt.cm.ScalarMappable(cmap=cmap, norm=norm),
    # ticks=[],
    cax=axs0cb,
    extend="max",
)
cbar.ax.set_ylabel(
    "zPower [a.u]",
    fontsize=7,
    rotation=270,
    labelpad=13,
)


######################################################## TEST ########################################################

for time, ax in enumerate(axs1[:-1]):

    plt.sca(ax)

    plot_tile_map(
        ax,
        power_pval,
        np.asarray([areas_dict[roi.lower()] for roi in power_pval.roi.data]),
        time,
        vmin=-5,
        vmax=5,
        cmap="seismic",
    )

    plt.xticks(fontsize=8)


import matplotlib

norm = matplotlib.colors.Normalize(vmin=-5, vmax=5)
cmap = matplotlib.cm.get_cmap("seismic")


cbar = plt.colorbar(
    mappable=plt.cm.ScalarMappable(cmap=cmap, norm=norm),
    # ticks=[],
    cax=axs1[5],
    extend="both",
)
cbar.ax.set_ylabel(
    "Fraction of significative differences in crackle rate",
    fontsize=7,
    rotation=270,
    labelpad=13,
)

######################################################## Total activity #############################################
plt.sca(axs5)
plt.fill_between(
    zci_task.times, zci_task.isel(bound=0), zci_task.isel(bound=1), alpha=0.3, color="b"
)
zci_task.mean("bound").plot(color="b", label="task")

plt.fill_between(
    zci_fix.times,
    zci_fix.isel(bound=0),
    zci_fix.isel(bound=1),
    alpha=0.3,
    color="orange",
)
zci_fix.mean("bound").plot(color="orange", label="fixation")

plt.legend(frameon=False, fontsize=6)
plt.title("27 Hz band", fontsize=8)

plt.ylabel("Total activation", fontsize=8, labelpad=-1)
plt.xlabel("Time [s]", fontsize=8)
[axs5.spines[key].set_visible(False) for key in ["top", "right"]]

######################################################## POWER TS ########################################################
plt.sca(axs3)
plot_rate_probability(
    P_b_task.sel(freqs=27).median("boot"),
    labels_task.sel(freqs=3),
    axs3,
    vmax=0.1,
    cmap="jet",
)
plt.xticks(fontsize=6)
plt.yticks(fontsize=6)
plt.xlabel("Time [s]", fontsize=8)
plt.title("Single-session clackle time-resolved probability", fontsize=10)

norm = matplotlib.colors.Normalize(vmin=0, vmax=0.7)
cmap = matplotlib.cm.get_cmap("jet")


cbar = plt.colorbar(
    mappable=plt.cm.ScalarMappable(cmap=cmap, norm=norm),
    # ticks=[],
    cax=axs3cb,
    extend="max",
)
cbar.ax.set_ylabel(
    "Power activation [a.u]",
    fontsize=7,
    rotation=270,
    labelpad=8,
)

######################################################## FACTORS ########################################################
for i in range(4):

    values = W_task.sel(freqs=3, components=i)
    areas = [a.lower() for a in values.roi.data]
    fmap = flatmap(values.data, areas)

    # Only plot colorbar for last column
    fmap.plot(
        axs4[i],
        ax_colorbar=None,
        cbar_title="Norm. entropy",
        alpha=0.6,
        vmin=0,
        vmax=0.3,
        colormap="Greys",
    )
    plt.title(f"factor {i + 1}")
# Factors
for i in range(4, 8):
    plt.sca(axs4[i])
    plt.plot(H_task.times, H_task.sel(freqs=3, components=i - 4), color="b")
    [axs4[i].spines[key].set_visible(False) for key in ["top", "right"]]
    plt.xlim(-0.5, 2)
    plt.xlabel("Time [s]")


plot.add_panel_letters(
    fig,
    axs0 + [axs1[0], axs5, axs3] + axs4,
    fontsize=12,
    xpos=[-0.1] * 13,
    ypos=[1.1] * 2 + [1.03] + [1.15] * 2 + [1.05] * 4 + [1.15] * 4,
)


bg = plot.Background(visible=False)

plt.savefig("figures/main/figure2.png", bbox_inches="tight")



