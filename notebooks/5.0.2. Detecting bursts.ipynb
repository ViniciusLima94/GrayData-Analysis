{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Algorithm to detect and characterize burst dynamics\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Path to the toolbox\n",
    "import sys; sys.path.insert(1, '/home/vinicius/storage1/projects/GrayData-Analysis')\n",
    "import os \n",
    "\n",
    "# GDa functions\n",
    "import GDa.stats.bursting                as     bst\n",
    "from   GDa.session                       import session\n",
    "from   GDa.temporal_network              import temporal_network\n",
    "from   GDa.util                          import smooth\n",
    "\n",
    "import matplotlib.pyplot                 as     plt\n",
    "import matplotlib\n",
    "import GDa.graphics.plot                 as     plot\n",
    "\n",
    "import numpy                             as     np\n",
    "import xarray                            as     xr\n",
    "\n",
    "\n",
    "from   tqdm                              import tqdm\n",
    "from   sklearn.manifold                  import TSNE\n",
    "from   scipy                             import stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SMALL_SIZE, MEDIUM_SIZE, BIGGER_SIZE = plot.set_plot_config()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create directory to save figures\n",
    "if not os.path.exists(\"img/n5.0.2\"):\n",
    "    os.makedirs(\"img/n5.0.2\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Detecting bursts (example)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x         = np.array([0,1,1,0,0,1,0,0,0,1,1,1,1,1,1,1,1,0,0,0,1,1,1])\n",
    "mask      = {}\n",
    "mask['1'] = np.array([1,1,1,1,1,1,1,1,1,1,1,1,0,0,0,0,0,0,0,0,0,0,0]).astype(bool)\n",
    "mask['2'] = np.logical_not(mask['1'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(5, 4), dpi=600)\n",
    "\n",
    "gs1 = fig.add_gridspec(nrows=1, ncols=1, left=0.05, right=0.95, bottom=0.45, top=0.95)\n",
    "gs2 = fig.add_gridspec(nrows=1, ncols=1, left=0.05, right=0.95, bottom=0.08, top=0.43)\n",
    "\n",
    "# Panel A\n",
    "ax1 = plt.subplot(gs1[0])\n",
    "png = plt.imread(\"img/n5.0.0/cartton_act.png\")\n",
    "plt.sca(ax1)\n",
    "im = plt.imshow(png, interpolation='none')\n",
    "plt.axis('off')    \n",
    "pad = 10\n",
    "plt.xlim(-pad, png.shape[1]+pad)\n",
    "plt.ylim(png.shape[0]+pad, -pad) \n",
    "\n",
    "# Panel B\n",
    "ax2 = plt.subplot(gs2[0])\n",
    "\n",
    "plt.sca(ax2)\n",
    "plt.vlines(np.arange(len(x))[x==1], 0, 1,  color='k', label='spike-train')\n",
    "#plt.plot(mask['1'], lw=1, label='Stage 1', color='blue')\n",
    "#plt.plot(mask['2'], lw=1, label='Stage 2', color='red')\n",
    "plt.hlines(1,-0.1,11.5,color=\"blue\")\n",
    "plt.hlines(1,11.5,22.1,color=\"red\")\n",
    "plt.vlines(11.5,-0.01,0.99,ls=\"--\", color=\"gray\")\n",
    "plt.xlim(-0.1,22.1)\n",
    "plt.ylim(-0.01,1.01)\n",
    "ax2.spines[\"top\"].set_visible(False)\n",
    "ax2.spines[\"right\"].set_visible(False)\n",
    "ax2.spines[\"left\"].set_visible(False)\n",
    "plt.yticks([])\n",
    "#plt.legend()\n",
    "\n",
    "bg = plot.Background(visible=False)\n",
    "plot.add_panel_letters(fig, axes=[ax1, ax2], fontsize=12,\n",
    "                       xpos=[0,0], ypos=[0.9, 1.05])\n",
    "bg.axes.text(0.3, 0.45, \"Stage 1\", ha='center', fontsize=MEDIUM_SIZE)\n",
    "bg.axes.text(0.73, 0.45, \"Stage 2\", ha='center', fontsize=MEDIUM_SIZE)\n",
    "\n",
    "plt.savefig(\"img/n5.0.2/example_burst_stats.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Finding the length of burst durations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'burst lengths = {bst.find_activation_sequences(x, dt=None,)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Finding the length of burst durations for segments of the spike-train using a mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx, key in enumerate(mask):\n",
    "    print(f'Mask {idx}, burst lengths = {bst.masked_find_activation_sequences(x, mask[key], dt=None, drop_edges=False)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Finding the length of burst durations for segments of the spike-train using a mask dropping the bursts in the edge between masks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx, key in enumerate(mask):\n",
    "    print(f'Mask {idx}, burst lengths = {bst.masked_find_activation_sequences(x, mask[key], dt=None, drop_edges=True)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy  as np\n",
    "import numba  as nb\n",
    "import xarray as xr\n",
    "from   frites.utils   import parallel_func\n",
    "\n",
    "@nb.jit(nopython=True)\n",
    "def _nan_pad(x, new_size):\n",
    "    return np.concatenate( (x, np.nan*np.ones(new_size-len(x))) )\n",
    "\n",
    "@nb.jit(nopython=True)\n",
    "def find_start_end(array, find_zeros=False):\n",
    "    \"\"\"\n",
    "    Given a binary array find the indexes where the sequences of ones start and begin if find_zeros is False. \n",
    "    Otherwise it will find the indexes where the sequences of zeros start and begin.\n",
    "    For instance, for the array [0,1,1,1,0,0], would return 1 and 3 respectively for find_zeros=False, \n",
    "    and 1 and 2 for find_zeros=True.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    array: array_like \n",
    "        Binary array.\n",
    "    find_zeros: bool | False\n",
    "        Wheter to find a sequence of zeros or ones\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    The matrix containing the start anb ending index \n",
    "    for each sequence of consecutive ones or zeros with shapes [n_seqs,2]\n",
    "    where n_seqs is the number of sequences found.\n",
    "    \"\"\"\n",
    "    if find_zeros: \n",
    "        _bounds = np.array([1])\n",
    "    else:\n",
    "        _bounds = np.array([0])\n",
    "\n",
    "    bounded     = np.hstack((_bounds, array, _bounds))\n",
    "    difs        = np.diff(bounded)\n",
    "    # get 1 at run starts and -1 at run ends if find_zeros is False\n",
    "    if not find_zeros:\n",
    "        run_starts, = np.where(difs > 0)\n",
    "        run_ends,   = np.where(difs < 0)\n",
    "    # get -1 at run starts and 1 at run ends if find_zeros is True\n",
    "    else:\n",
    "        run_starts, = np.where(difs < 0)\n",
    "        run_ends,   = np.where(difs > 0)\n",
    "    return np.vstack((run_starts,run_ends)).T\n",
    "\n",
    "@nb.jit(nopython=True)\n",
    "def find_activation_sequences(spike_train, dt=None):\n",
    "    \"\"\"\n",
    "    Given a spike-train, it finds the length of all activations in it.\n",
    "    For example, for the following spike-train: x = {0111000011000011111},\n",
    "    the array with the corresponding sequences of activations (ones) will be \n",
    "    returned: [3, 2, 5] (times dt if this parameter is provided).\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    spike_train: array_like\n",
    "        The binary spike train.\n",
    "    dt: int | None\n",
    "        If provided the returned array with the length of activations will be given in seconds.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    act_lengths: array_like\n",
    "        Array containing the length of activations with shape [n_seqs]\n",
    "        where n_seqs is the number of sequences found.\n",
    "    \"\"\"\n",
    "\n",
    "    # If no dt is specified it is set to 1\n",
    "    if dt is None:\n",
    "        dt = 1\n",
    "    out         = find_start_end(spike_train)\n",
    "    act_lengths = (out[:,1]-out[:,0])*dt\n",
    "\n",
    "    return act_lengths\n",
    "\n",
    "#@nb.jit(nopython=True)\n",
    "def masked_find_activation_sequences(spike_train, mask, dt=None, drop_edges=False, pad=False):\n",
    "    \"\"\"\n",
    "    Similar to \"find_activation_sequences\" but a mask is applied to the spike_train while computing\n",
    "    the size of the activation sequences.'\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    spike_train: array_like\n",
    "        The binary spike train.\n",
    "    mask: array_like\n",
    "        Binary mask applied to the spike-train.\n",
    "    dt: int | None\n",
    "        If provided the returned array with the length of activations will be given in seconds.\n",
    "    drop_edges: bool | False\n",
    "        If True will remove the size of the last burst size in case the spike trains ends at one.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    act_lengths: array_like\n",
    "        Array containing the length of activations with shape [n_seqs]\n",
    "        where n_seqs is the number of sequences found.\n",
    "    \"\"\"\n",
    "\n",
    "    # Assure that mask is type bool\n",
    "    mask = mask.astype(np.bool_)\n",
    "\n",
    "    # Find the size of the activations lengths for the masked spike_train\n",
    "    act_lengths = find_activation_sequences(spike_train[mask], dt=dt)\n",
    "    # If drop_edges is true it will check if activation at the \n",
    "    # left and right edges crosses the mask limits.\n",
    "    if len(act_lengths)>0 and drop_edges:\n",
    "        idx, = np.where(mask==True)\n",
    "        i,j  = idx[0], idx[-1]\n",
    "        # If the mask starts at the beggining of the array\n",
    "        # there is no possibility to cross from the left side\n",
    "        if i>=1:\n",
    "            if spike_train[i-1]==1 and spike_train[i]==1:\n",
    "                act_lengths = np.delete(act_lengths,0)\n",
    "        # If the mask ends at the ending of the array\n",
    "        # there is no possibility to cross from the right side\n",
    "        if j<len(mask)-1:\n",
    "            if spike_train[j]==1 and spike_train[j+1]==1:\n",
    "                act_lengths = np.delete(act_lengths,-1)\n",
    "                 \n",
    "    if pad:\n",
    "        _new_size   = len(spike_train)//2+1\n",
    "        act_lengths = _nan_pad(act_lengths, _new_size)\n",
    "                \n",
    "    return act_lengths\n",
    "\n",
    "def tensor_find_activation_sequences(spike_train, mask, dt=None, drop_edges=False, pad=False, n_jobs=1):\n",
    "    \"\"\"\n",
    "    A wrapper from \"masked_find_activation_sequences\" to run for tensor data \n",
    "    of shape [links, trials, time].\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    spike_train: array_like\n",
    "        The binary spike train.\n",
    "    mask: array_like\n",
    "        Binary mask applied to the spike-train with size [trials, time]. For more than one mask\n",
    "        a dicitionary should be provided where for each key an array with size [trials, time]\n",
    "        is provided.\n",
    "    dt: int | None\n",
    "        If provided the returned array with the length of activations will be given in seconds.\n",
    "    drop_edges: bool | False\n",
    "        If True will remove the size of the last burst size in case the spike trains ends at one.\n",
    "    n_jobs: int | 1\n",
    "        Number of threads to use\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    act_lengths: array_like\n",
    "        Array containing the length of activations for each link and trial\n",
    "    \"\"\"\n",
    "\n",
    "    # Checking inputs\n",
    "    assert isinstance(spike_train, (np.ndarray, xr.DataArray))\n",
    "    assert isinstance(mask, (dict, np.ndarray, xr.DataArray))\n",
    "    assert spike_train.ndim == 3\n",
    "\n",
    "    # Number of edges\n",
    "    n_edges = spike_train.shape[0]\n",
    "    if pad:\n",
    "        _new_size   = len(spike_train)//2+1\n",
    "\n",
    "    # Find the activation sequences for each edge\n",
    "    #@nb.jit(nopython=True)\n",
    "    def _edgewise(x, m):\n",
    "        act_lengths = np.empty((x.shape[0],_new_size))\n",
    "        # For each trial\n",
    "        for i in range(x.shape[0]):\n",
    "            #act_lengths += [act_lengths, masked_find_activation_sequences(x[i,...], m[i,...], drop_edges=drop_edges, dt=dt)]\n",
    "            #act_lengths = np.concatenate( act_lengths, masked_find_activation_sequences(x[i,...], m[i,...], drop_edges=drop_edges, dt=dt) )\n",
    "            #act_lengths += [np.apply_along_axis(masked_find_activation_sequences, -1, \n",
    "            #                x[i,...], m[i,...], drop_edges=drop_edges, pad=pad,\n",
    "            #                dt=dt)]\n",
    "            act_lengths[i] = masked_find_activation_sequences(x[i,...], m[i,...], drop_edges=drop_edges, pad=pad, dt=dt)\n",
    "            #print(f\"{len(masked_find_activation_sequences(x[i,...], m[i,...], drop_edges=drop_edges, pad=pad, dt=dt))}\")\n",
    "        #act_lengths = np.concatenate( act_lengths, axis=0 )\n",
    "        return act_lengths \n",
    "\n",
    "    # Computed in parallel for each edge\n",
    "    parallel, p_fun = parallel_func(\n",
    "    _edgewise, n_jobs=n_jobs, verbose=False,\n",
    "    total=n_edges)\n",
    "\n",
    "    if isinstance(mask, (np.ndarray, xr.DataArray)):\n",
    "        assert len(mask.shape) == 2\n",
    "        act_lengths = parallel(p_fun(spike_train[e,...], mask) for e in range(n_edges))\n",
    "    elif isinstance(mask, dict):\n",
    "        # Use the same keys as the mask\n",
    "        act_lengths = dict.fromkeys(mask.keys())\n",
    "        for key in mask.keys():\n",
    "            assert len(mask[key].shape) == 2\n",
    "            act_lengths[key] = parallel(p_fun(spike_train[e,...], mask[key]) for e in range(n_edges))\n",
    "    return act_lengths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spike_train = np.random.rand(1176,540,20)>0.5\n",
    "mask        = np.zeros((540,20))\n",
    "mask[:,:10] = 1\n",
    "mask        = mask.astype(bool)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "find_start_end(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "find_activation_sequences(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%timeit masked_find_activation_sequences(spike_train[0,0], mask[0], dt=None, drop_edges=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tensor_find_activation_sequences(spike_train, mask, dt=None, drop_edges=False, pad=True, n_jobs=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def masked_per_trial():\n",
    "    np.apply_along_axis(masked_find_activation_sequences, -1, \n",
    "                        spike_train[0,0], mask[0], drop_edges=False, \n",
    "                        dt=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spike_train[0,0,:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.array([1,2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(spike_train[0,0])//2+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@nb.jit(nopython=True)\n",
    "def nan_pad(x, new_size):\n",
    "    return np.concatenate( (a, np.nan*np.ones(new_size-len(x))) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "masked_find_activation_sequences(spike_train[0,0], mask[0], dt=None, drop_edges=False, pad=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@nb.jit(nopython=True)\n",
    "def _nan_pad(x, new_size):\n",
    "    return np.concatenate( (x, np.nan*np.ones(new_size-len(x))) )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_nan_pad(spike_train, 25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s=[]\n",
    "for i in range(540):\n",
    "    s.append( len(masked_find_activation_sequences(spike_train[0,i], mask[0], drop_edges=False, pad=True,\n",
    "                        dt=None)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@nb.jit(nopython=True)\n",
    "def _edgewise(x, m):\n",
    "    act_lengths = np.zeros((x.shape[0],11), dtype=np.int8)\n",
    "    # For each trial\n",
    "    for i in range(x.shape[0]):\n",
    "        act_lengths[i] = masked_find_activation_sequences(x[i,...], m[i,...], drop_edges=True, pad=True, dt=1)\n",
    "    return act_lengths "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_edgewise(spike_train[0],mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
